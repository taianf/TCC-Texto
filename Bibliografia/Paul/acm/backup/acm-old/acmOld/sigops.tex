\documentclass{acm_proc_article-sp}

%\usepackage{wso}
%\usepackage{graphicx, color}
%\usepackage[T1]{fontenc}

\usepackage{color}

\newcommand{\col}[1]{\textcolor{red}{#1}}
\newcommand{\cod}[1]{\hspace{0.1cm}\texttt{#1}}
\newcommand{\ing}[1]{\emph{#1}}
\newcommand{\kernel}{\ing{kernel}}
\newcommand{\kernell}{\ing{kernel} }
\newcommand{\preempt}{{Preempt-RT}}
\newcommand{\preemptt}{{Preempt-RT }}
\newcommand{\nanokernel}{\ing{nanokernel}}
\newcommand{\nanokernell}{\ing{nanokernel} }

\usepackage[font=normalsize, justification=Centering, singlelinecheck=false]{caption}
\usepackage[captionskip=1pt]{subfig}
%\renewcommand{\captionfont}{\sffamily\small\bfseries}


\begin{document}

% \usepackage{graphicx,url}

% \usepackage[brazil]{babel} \usepackage[latin1]{inputenc}

     
%\sloppy

\title{Evaluation of Interrupt Handling Timeliness\\in Real-Time Linux Operating Systems}

\numberofauthors{3}
\author{
\alignauthor
Paul Regnier\\%\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{Distributed Systems Laboratory (LaSiD)}\\
       \affaddr{Computer Science Department (DCC)}\\
%       \affaddr{Campus de Ondina, 40170-110, Salvador-BA, Brazil}\\
       \affaddr{Federal University of Bahia}\\
       \email{pregnier@ufba.br}
%
\alignauthor
George Lima \\%\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{Distributed Systems Laboratory (LaSiD)}\\
       \affaddr{Computer Science Department (DCC)}\\
%       \affaddr{Campus de Ondina, 40170-110, Salvador-BA, Brazil}\\
       \affaddr{Federal University of Bahia}\\
       \email{gmlima@ufba.br}
%
\alignauthor
Luciano Barreto \\%\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{Distributed Systems Laboratory (LaSiD)}\\
       \affaddr{Computer Science Department (DCC)}\\
%       \affaddr{Campus de Ondina, 40170-110, Salvador-BA, Brazil}\\
       \affaddr{Federal University of Bahia}\\
       \email{lportoba@ufba.br}
}

\date{30 July 1999}


\maketitle

\begin{abstract}
  Several real-time Linux extensions can be found nowadays. Two of them have
  received special attention recently, the patches Preempt-RT and Xenomai. This
  paper evaluates to what extent they provide deterministic guarantees when reacting
  to external events, an essential characteristic when it comes to real-time
  systems. To do that we define a simple but effective experimental
  approach. Obtained results indicate that Preempt-RT is more prone to temporal
  variations than Xenomai when the system is subject to overload scenarios.
\end{abstract}
     

\section{Introduction}

% Os sistemas de tempo real englobam diversas aplicações ligadas às áreas de
% telecomunicações, multimídia, indústria, transporte, medicina, etc.  Para tais
% sistemas, a escolha adequada de Sistemas Operacionais de Tempo Real (SOTR) constitui
% aspecto fundamental de projeto. Apesar da importância da evolução tecnológica do
% hardware, certas inovações podem introduzir empecilhos para a construção de
% SOTR. Por exemplo, os adventos de memória \ing{cache}, acesso direto à memória
% (DMA), co-processamento, predição de instruções, unidades \ing{multicore},
% \ing{pipelines} e execução fora de ordem constituem fontes não-desprezíveis de
% indeterminismo \cite{Liu00, Pratt04}.  Assim, a construção de um sistema operacional
% de uso genérico com foco em previsibilidade temporal permanece um desafio de
% pesquisa atual.

Real-time systems include various applications related to areas of
telecommunications, multimedia, industry, transport, medicine, etc. For such
systems, the choice of Real-Time Operating Systems (RTOS) is a fundamental aspect of
design. Despite the importance of technological hardware developments, some
innovations may introduce obstacles to the construction of RTOS. For example, the
cache memory access, direct memory access (DMA), co-processing, prediction of
instructions, multi-core units, pipelines and executions out of order are
non-negligible sources of indeterminism \cite{Liu00, Pratt04}. Thus, the
construction of a general purpose operating system with a focus on timing
predictability remains a challenge of current research.

% Apesar de sua difusão e popularidade, o \kernell padrão do Linux \cite{Bovet05}
% falha na oferta de garantias temporais típicas dos sistemas de tempo real críticos
% \cite{Marchesotti06, Abeni02}. Para contornar esse problema, várias abordagens foram
% desenvolvidas com o intuito de aumentar o grau de previsibilidade temporal do Linux
% \cite{PreemptRT, Xenomai, Dozio03, rtLinux, Fry07, Calandrino06}. A evolução rápida
% e a diversidade das soluções disponíveis apela para estudos comparativos que
% permitam avaliar o determinismo oferecido por cada plataforma de forma a auxiliar o
% projetista de sistemas de tempo real na escolha apropriada da distribuição a ser
% utilizada.

Despite its spread and popularity, the \kernell standard Linux \cite{Bovet05}
fails in the provision of timing guarantees typical of real-time critical systems  
\cite{Marchesotti06, Abeni02}. To circumvent this problem, several
approaches have been developed in order to increase the timing predictability of Linux
\cite{PreemptRT, Xenomai, Dozio03, rtLinux, Fry07, Calandrino06}. The rapid
evolution and diversity of solutions available calls for comparative studies to
assess the determinism offered by each platform in order to help the designer of
real time systems in choosing the appropriate solution to be used.

% Este trabalho tem por objetivo apresentar e comparar os \ing{patches} do \kernell
% Linux \preemptt (Linux$^{\mathbf{Prt}}$) \cite{PreemptRT} e Xenomai
% (Linux$^{\mathbf{Xen}}$) \cite{Xenomai} , desenvolvidos para aumentar a
% previsibilidade do Linux.  As principais contribuições deste trabalho são: (i) a
% proposta de uma metodologia de avaliação simples baseada em software e hardware de
% prateleira, que utiliza uma sobrecarga do processador através de carga de
% processamento, de entrada e saída, e de interrupção; (ii) a obtenção de resultados
% que confirmam a capacidade de Linux$^{\mathbf{Xen}}$ em oferecer garantias temporais
% críticas, e (iii) a confirmação que, em situação de carga intensa,
% Linux$^{\mathbf{Prt}}$ não consegue oferecer garantias temporais de maneira tão
% determinística quanto Linux$^{\mathbf{Xen}}$.

This paper aims to present and compare the \kernell Linux patches \preemptt
(Linux$^{\mathbf{Prt}}$ \cite{PreemptRT} and Xenomai (Linux$^{\mathbf{Xen}}$)
\cite{Xenomai}, developed to increase the predictability of Linux. The main
contribution of this work are: (i) the proposal of an evaluation methodology, based
on simple software and hardware cots, which uses an overload of the processor load
through I/O processing and interruption, (ii) the assessments of results that
confirm the ability of Linux$^{\mathbf{Xen}}$ Xen to offer critical time guarantees,
and (iii) the confirmation that, in situations of intense load,
Linux$^{\mathbf{Prt}}$ does not offer timing guarantees as predictable as
Linux$^{\mathbf{Xen}}$.

% A Seção \ref{sec:compTemp} descreve alguns fatores de imprevisibilidade do Linux e
% define as métricas adotadas para a comparação de Linux$^{\mathbf{Prt}}$ e
% Linux$^{\mathbf{Xen}}$. Estas duas plataformas são descritas nas Seções
% \ref{sec:preemptRT} e \ref{sec:xenomai}.  Em seguida, a descrição da metodologia de
% experimentação na Seção \ref{sec:metod} precede a apresentação dos resultados
% experimentais na Seção \ref{cap:platEstud}. Finalmente, a Seção \ref{sec:trabRel}
% apresenta brevemente os trabalhos relacionados e a Seção \ref{sec:conc} conclui este
% trabalho.

Section \ref{sec:compTemp} describes some factors of unpredictability of Linux and
defines the metrics adopted for the comparison of Linux$^{\mathbf{Prt}}$ and
Linux$^{\mathbf{Xen}}$. These two platforms then are described in Sections
\ref{sec:preemptRT} and \ref{sec:xenomai}. Thereafter, the description of the
methodology of experimentation in Section \ref{sec:metod} precedes the presentation
of experimental results in Section \ref{cap:platEstud}. Finally, Section
\ref{sec:trabRel} briefly introduced the related work and Section \ref{sec:conc}
concludes this work.

\section{Comparison metrics}
\label{sec:compTemp}

% O método convencional utilizado para minimizar o impacto das interrupções sobre a
% execução dos processos consiste em dividir a execução do tratador de interrupção em
% duas partes. A primeira parte executa operações críticas de forma imediata e com as
% interrupções desabilitadas, o que constitui a \textbf{seção crítica} do
% tratador. Eventualmente, pode-se reabilitar as interrupções de modo a permitir
% preempção, tomando-se o cuidado de garantir o acesso controlado aos dados
% compartilhados através de \ing{locks}.  Na segunda parte, as operações não-críticas
% são possivelmente adiadas e executadas com as interrupções habilitadas.  No Linux,
% estas execuções postergadas são chamadas de \textbf{\emph{softirqs}}.

The conventional method used to minimize the impact of interruptions on the
implementation of processes is to divide the implementation of the interruption
handler into two parts. The first part, refered to as the \textbf{critical section}
of the handler, run critical operations immediatly, with interruptions
disabled. Eventually, one can enable interruptions during par of the critical
section in order to allow preemption. However, such implementation must rely on
locks to ensure a controlled access to shared data. The second part of the handler is dedicated
to non-critical operations. Its execution can be delayed, and normally happens with the interruptions
enabled. In Linux, such delayed executions are called \textbf{\emph{softirqs}}.

\subsection{Interrupt latency}
\label{sec:latIRQ}

% Uma requisição de interrupção, ou simplesmente \textbf{interrupção}, do processador
% por um dispositivo de \ing{hardware} é assíncrona e pode acontecer em qualquer
% momento do ciclo de execução do processador. Em particular, tal requisição pode
% ocorrer enquanto a seção crítica do tratador de outra interrupção estiver
% executando, com as interrupções desabilitadas. Tal cenário pode provocar uma
% latência não determinística para a detecção da requisição de interrupção pelo
% processador.

An interrupt request, or simply \textbf{interruption}, of the processor by a device
is tipically asynchronous and can happen at any time during the processor execution
cycle. In particular, such a request can occur while the critical section of another
interrupt handler is running, with interruptions disabled. This scenario may cause a
non deterministic latency for the detection of interrupt request by the processor.

% O tempo decorrido entre o instante no qual uma requisição de interrupção acontece e
% o início da execução do tratador associado é chamado de \textbf{latência de
%   interrupção}.  Esta grandeza foi contemplada como métrica para efeito de
% comparação das plataformas estudadas, pois caracteriza a capacidade do sistema para
% reagir a eventos externos.

The time interval between the instant in which an interrupt request happens and the
beginning of its associated handler execution is called \textbf{interrupt
  latency}. As it characterizes the system's capability to react to
external events, this quantity was regarded as a metric for the purpose of the comparison
of the studied platforms .

\subsection{Activation latency}
\label{sec:latAtiv}

% No \kernell Linux, logo após o término da seção crítica do tratador de interrupção,
% o \ing{softirq} correspondente está apto a executar. No entanto, entre o instante no
% qual a seção crítica termina e o instante no qual o \ing{softirq} começa a executar,
% outras interrupções podem acontecer, provocando um possível atraso na execução dos
% \ing{softirqs}.

In the \kernell Linux, just after the end of the interrupt handler critical section,
the associated \emph{softirq} becomes able to perform. However, between the instant
in which the critical section execution terminates and the instant in which deferred
\emph{softirqs} begins to execute, others interruptions may occur, causing a possible
delay in the \emph{softirqs} execution.

% Nas plataformas de tempo real, eventos de temporizadores ou de \ing{hardware} são
% utilizados para disparar tarefas, num modelo similar aos \ing{softirqs}. Tal tarefa,
% muitas vezes periódica, fica suspensa a espera de um evento.  Quando o evento
% ocorre, a requisição de interrupção associada aciona o tratador correspondente que,
% por sua vez, acorda a tarefa. O intervalo de tempo entre os instantes de ocorrência
% do evento e o início da execução da tarefa associada é chamada de \textbf{latência
%   de ativação}. Assim como no caso dos \ing{softirqs}, a latência de ativação pode
% ser aumentada pela ocorrência de interrupções. Além disso, a execução de outros
% \ing{softirqs} pode ser escalonada de acordo com alguma política (ex: FIFO,
% prioridade fixa), o que pode também gerar interferências na latência de ativação.
% Assim como a latência de interrupção, a latência de ativação caracteriza a
% capacidade de um sistema para reagir a eventos externos.

In real-time platforms, timeouts events or hardware events are used to trigger
tasks, in a similar manner as for \emph{softirqs}. Such a task, often periodic, is
suspended while waiting for some event. When this event occurs, the associated
interrupt request triggers the corresponding handler which, in turn, wakes the task
up. The time interval between the instant when the event occur and the beginning of
the execution of the associated task is called \textbf{activation latency}. As for
the \emph{softirqs}, the activation latency may be increased by the occurrence of
interruptions. Furthermore, the execution of other \emph{softirqs} may be scheduled
according to some policy (eg FIFO, fixed priority), which can also generate
interference in the activation latency. Like the interrupt latency, the activation
latency characterizes the capability of a system to react to external events. Thus,
this quantity was also regarded as a metric for the purpose of the comparison of the
studied platforms.

\section{Linux Preempt-RT}
\label{sec:preemptRT}

% Para prover precisão temporal, Linux$^{\mathbf{Prt}}$ \cite{McKenney05, Rostedt07}
% utiliza uma nova implementação dos temporizadores de alta resolução desenvolvida por
% Thomas Gleixner \cite{Kernel}.  Baseado no valor no registrador \ing{Time Stamp
%   Counter} (TSC) da arquitetura Intel ou em relógios de alta resolução, esta
% implementação oferece uma API que permite obter valores temporais com resolução de
% micro-segundos.  De acordo com resultados apresentados \cite{Rostedt07, Siro07}, os
% tempos de latência de ativação obtidos usando esta API são da ordem de algumas
% dezenas de $\mu s$ nos computadores atuais.

To provide accurate time measurement, Linux$^{\mathbf{Prt}}$ \cite{McKenney05,
  Rostedt07} uses a new implementation of high resolution timers developed by Thomas
Gleixner \cite{Kernel}. Either based on the value of the Time Stamp Counter (TSC)
register of the Intel architecture or on high resolution clocks, the implementation
offers an API which allows for micro-seconds time resolution measurement. According
to results presented \cite{Rostedt07, Siro07}, the activation latencies obtained
using this API are of the order of some tens of $\mu s$ in current computers.

% Linux$^{\mathbf{Prt}}$ comporta várias modificações que tornam o \kernell totalmente
% preemptível. Dessa forma, assim que um processo de mais alta prioridade é
% desbloqueado, este consegue adquirir o processador com latência mínima, sem
% necessidade de espera pelo fim da execução de um processo de menor prioridade, mesmo
% que este esteja executando em modo \kernel. Para limitar os efeitos de
% imprevisibilidade causados por recursos compartilhados, Linux$^{\mathbf{Prt}}$
% modifica as primitivas de sincronização de maneira a permitir a implementação de um
% protocolo baseado em herança de prioridade \cite{Sha90}.

Linux$^{\mathbf{Prt}}$ includes several changes that make the \kernell totally
preemptable. Thus, as soon as a process of highest priority is released, it can
acquire the processor with minimal latency, with no need to wait for the end of the
execution of a process of lower priority, even if such a process is running in
\kernell mode. For instance, in order to limit the effects of unpredictability
caused by shared resources, Linux$^{\mathbf{Prt}}$ modify the primitives of
synchronization to enable the implementation of a protocol based on inheritance of
priority \cite{Sha90}.


%PAUL
% Em relação à latência de interrupção, Linux$^{\mathbf{Prt}}$ utiliza \ing{threads}
% de interrupções. Quando uma linha de interrupção é iniciada, um \ing{thread} é
% criado para gerenciar as requisições de interrupção associadas a esta linha.  Na
% ocorrência de uma requisição, o tratador associado mascara a requisição, acorda o
% \ing{thread} da interrupção e volta para o código interrompido. Desta forma, a parte
% crítica do tratador de interrupção é reduzida ao seu mínimo e a latência causada
% pela sua execução, além de ser breve, é determinística. Em algum momento futuro, o
% \ing{thread} de interrupção acordado é escalonado, de acordo com a sua prioridade,
% dando espaço para indeterminismo, o que será objeto do presente estudo.
 
As for the interrupt latency, Linux$^{\mathbf{Prt}}$ uses threads of interruptions.
When an IRQ (Interrupt Request) line is initialized, a thread is created to manage
the interrupt requests associated with this line. When a request occur, the
associated handler masks the request, wakes the associated thread up and returns to
the interrupted code. Thus, the critical part of the interrupt handler is reduced to
its minimum and the latency caused by its execution is both short and
deterministic. Eventually, the interrupt thread is scheduled, according to its
priority, giving room for unpredictability, which will be object of this study.

% Usando programas corretamente escritos, respeitando as regras de programação de
% Linux$^{\mathbf{Prt}}$ e alocando os recursos de acordo com os requisitos temporais,
% a solução Linux$^{\mathbf{Prt}}$ tem a vantagem de oferecer o ambiente de
% programação do sistema Linux, dando acesso às bibliotecas C e ao conjunto de
% software disponível para este sistema.

Using programs correctly written, respecting the rules of Linux$^{\mathbf{Prt}}$
programming and allocating resources in accordance with the time requirements, the
Linux$^{\mathbf{Prt}}$ platform has the advantage to offer the programming
environment of the Linux operating system, giving access to C libraries and to
the many available softwares for this system.

\section{Linux Xenomai}
\label{sec:xenomai}

% Diferentemente de Linux$^{\mathbf{Prt}}$, a plataforma Linux$^{\mathbf{Xen}}$
% utiliza uma abordagem baseada no mecanismo de indireção das interrupções introduzido
% na técnica de ``proteção otimista das interrupções'' \cite{Stodolsky93}.  Quando uma
% requisição de interrupção acontece, a camada de indireção, também chamada de
% \nanokernel, identifica se esta é relativa a uma tarefa de tempo real ou se é
% destinada a um processo do Linux. No primeiro caso, o tratador da interrupção é
% executado imediatamente. Caso contrário, a requisição é enfileirada e, em algum
% momento futuro, entregue para o Linux quando inexistirem tarefas de tempo
% real. Quando o Linux precisa desabilitar as interrupções, o \nanokernell apenas
% deixa o Linux acreditar que as interrupções estão desabilitadas. No entanto, o
% \nanokernell continua a interceptar qualquer interrupção de \ing{hardware}.  Nesta
% ocorrência, a interrupção é tratada imediatamente se for destinada a uma tarefa de
% tempo real. Caso contrário, a interrupção é enfileirada, até que o \kernell Linux
% reabilite suas interrupções.

Unlike Linux$^{\mathbf{Prt}}$, the Linux$^{\mathbf{Xen}}$ platform uses an approach
based on the interrupt indirection mechanism introduced in the technique of
``optimistic interrupt protection '' \cite{Stodolsky93}.  When an interrupt request
happens, the indirection layer, also called the \nanokernel, determines if the
request is destinated to a real time task or if is is directed to a Linux
process. In the first case, the interrupt handler is executed
immediately. Otherwise, the request is enqueued and eventually delivered to Linux
when no real time task is pending. Whenever the Linux \kernell must disable
interruptions, the \nanokernell just let Linux believe that the interruptions are
disabled. However, the \nanokernell continues to intercept any interruption of
hardware. In this case, the interruption is treated immediately if it is directed to
a real time task. Otherwise, the interruption is enqueued until the \kernell Linux
get back to enable interruptions.

% Para a implementação do \nanokernel, Linux$^{\mathbf{Xen}}$ utiliza uma camada de
% virtualização dos recursos chamada Adeos (\ing{Adaptative Domain Environment for
%   Operating Systems}) \cite{Yaghmour01}.  O \ing{patch} Adeos facilita o
% compartilhamento e o uso dos recursos de \ing{hardware} e oferece uma interface de
% programação simples e independente da arquitetura.  Resumidamente, Adeos é baseado
% nos conceitos de domínio e de canal hierárquico de interrupção. Um domínio
% caracteriza um ambiente de execução isolado, no qual pode-se executar programas ou
% até mesmo sistemas operacionais completos.  O canal hierárquico de interrupção,
% chamado \ing{ipipe}, serve para priorizar a entrega da interrupções entre os
% domínios. Quando um domínio se registra no Adeos, ele é colocado numa posição no
% \ing{ipipe} de acordo com os seus requisitos temporais.  Adeos utiliza então o
% mecanismo de indireção das interrupções para organizar a entrega hierárquica das
% interrupções, seguindo a ordem de prioridade dos domínios.

For the implementation of the \nanokernel, Linux$^{\mathbf{Xen}}$ uses a layer of
virtualization of resources called Adeos (Adaptative Domain Environment for
Operating Systems) \cite{Yaghmour01}. The patch Adeos facilitates the sharing and
use of hardware and provides an integrated programming simple and independent of
architecture. In short, Adeos is based on the concepts of domain and hierarchical
interrupt pipeline. A domain features an isolated environment for execution, in
which one can run programs or even a complete operating systems. The hierarquical
interrupt pipeline, called \textbf{ipipe}, serves to prioritize the delivery of
interruptions between domains. When a domain is registered in Adeos, it is allocated
a position in the ipipe according to its time requirements. Adeos then uses the
mechanism of interrupt indirection to organize the delivery of interrupts
hierarchically, according to the domains priorities.

% Os serviços de tempo real de Linux$^{\mathbf{Xen}}$ correspondem ao domínio mais
% prioritário do \ing{ipipe}, chamado ``domínio primário''.  Este domínio corresponde,
% portanto, ao núcleo de tempo real no qual as tarefas são executadas em modo
% protegido.

The real-time services of Linux$^{\mathbf{Xen}}$ correspond to the domain of highest
priority in the ipipe, called ``primary'' domain. This domain corresponds therefore
to the real time nucleus in which tasks are executed in protected mode.

% O ``domínio secundário'', por sua vez, corresponde ao \kernell Linux, no qual o
% conjunto de bibliotecas e software usual do Linux está disponível.  Em
% contrapartida, as garantias temporais são mais fracas, dado que o código pode
% utilizar as chamadas de sistemas bloqueantes do Linux.

The ``secondary domain'', in turn, refers to the \kernell Linux, in which the set of
usual Linux software libraries is available. However, the timing guarantees
are weaker, given that the code can use the blocking system calls of Linux.

% A implementação dos serviços de tempo real em modo usuário se baseia no mecanismo
% de herança de prioridade e num domínio intermediário, chamado ``escudo de
% interrupção'' que garante as seguintes propriedades: (i) a política de prioridade
% utilizada para as tarefas de tempo real, e para o escalonador associado, é comum
% aos dois domínios; e (ii) as interrupções de \ing{hardware} não podem impedir a
% execução de uma tarefa prioritária enquanto ela estiver no domínio secundário.


\section{Experimental methodology}
\label{sec:metod}

% Em geral, realizar medições precisas de tempo no nível dos tratadores de interrupção
% pode não ser tão simples.  De fato, o instante exato no qual uma requisição de
% interrupção acontece é de difícil medição, pois tal evento é assíncrono e pode ser
% causado por qualquer dispositivo de \ing{hardware}. Para obter medidas das latências
% de interrupção e ativação confiáveis com alto grau de precisão, aparelhos externos,
% tais como osciloscópios ou outros computadores, são necessários. Visto que o
% objetivo do presente trabalho foi caracterizar e comparar o grau de determinismo das
% plataformas operacionais estudadas, adotou-se uma metodologia experimental simples e
% efetiva, que pode ser reproduzida facilmente em outros contextos.

\begin{figure*}[t]
  \centering {\scalebox{1}{\input{fig/dispExp.pstex_t}}}
  \caption{Interrupt and activation latencies measurement at station $E_M$} \label{fig:dispExp}
\end{figure*}

In general, perform accurate time measurements at the level of the interrupt handler
may not be as simple. In fact, the exact instant in which a interrupt request
happens is difficult to measure, as this event is asynchronous and can be caused by
any hardware device. To obtain reliable interrupt and activation latency
measurements with a high degree of accuracy, external devices such as scopes or
other computers, are needed. Since the objective of this work was to characterize and
compare the degree of determinism of operational platforms studied, a simple and
effective experimental methodology was first adopted, which can be easily replicated in
other contexts. A second experiment, based on an more elaborated measurement strategy
was used to assess the validity of obtained results.


\subsection{First experimental configuration}
\label{sec:exp1}

% O dispositivo experimental utilizou três estações: (1) a estação de medição 
% na qual os dados foram coletados e onde temos uma tarefa de tempo real $\tau$ à
% espera de eventos externos; (2) a estação de disparo $E_D$, que foi utilizada para
% enviar pacotes Ethernet com uma freqüência fixa à estação $E_M$; e (3) a estação de
% carga $E_C$, utilizada para criar uma carga de interrupção na estação $E_M$. As
% estações de disparo e carga foram conectadas a estação de medição por duas rede
% Ethernet distintas, utilizando duas placas de redes ($eth_0$ e $eth_1$), conforme
% ilustrado no diagrama da Figura \ref{fig:config}.


\begin{figure}[tbh]
  \centering {\scalebox{1}{\input{fig/config.pstex_t}}}
  \caption{First experimental configuration}
  \label{fig:config}
\end{figure}


The first experiment use three stations:
\begin{enumerate}
\item The triggering station $E_T$ is used to send Ethernet packets with a fixed
  frequency to station $E_M$;
\item The measurement station $E_M$ where latencies
are measured and where a real time task $\tau$ is waiting for external
events;
\item The loader station $E_L$ is used to create an interrupt request load at station
  $E_M$.
\end{enumerate}

The $E_T$ and $E_L$ stations are connected to the $E_M$ station by two
  separate Ethernet network, using two Ethernet device ($eth_0$ and $eth_1$), as
  illustrated by Figure \ref{fig:config}.

% As chegadas dos pacotes enviados por $E_D$ em $E_M$ servem para disparar uma cascata
% de eventos na estação $E_M$, permitindo a simulação de eventos externos via sua
% porta paralela (PP). Mais explicitamente, cada chegada de um pacote Ethernet em
% $eth_0$ foi utilizada para disparar uma requisição de interrupção na PP, escrevendo
% no pino de interrupção desta porta (ver Figura \ref{fig:dispExp}). Esta escrita foi
% realizada pelo próprio tratador $T_{eth_0}$ de interrupção da placa $eth_0$.  O
% instante $t_1$ de escrita no pino de interrupção da PP pelo tratador $T_{eth_0}$
% constitui então o início da seqüência de eventos utilizados para medir as latências
% de interrupção ($Lat_{irq}$) e de ativação ($Lat_{ativ}$). Vale observar que não
% existe relação entre a chegada de pacotes na placa $eth_0$ de $E_M$ e a atividade
% sendo executada nesta estação.

The arrivals of packages sent by station $E_T$ serve to trigger a cascade of events
at station $E_M$, allowing the simulation of external events via its parallel port
(PP). More explicitly, each arrival of a package at device $eth_0$ is used to
trigger an interrupt request to the PP, setting its IRQ line (see Figure
\ref{fig:dispExp}):  in the interrupt handler of the $eth_0$ network device, the IRQ
line of the parallel port is set and the corresponding instant $t_1$ of the
interrupt request is memorized.  Thereafter, this initial event starts a sequence of two
events used to measure the latency of ($Lat_{irq}$) and activation ($Lat_{ativ}$)
activate). It is worth noting that there is no relationship between the arrival of packages at
the $eth_0$ device and the $E_M$ processing activity.


% As medidas seguiram o seguinte roteiro, ilustrado pela Figura \ref{fig:dispExp}:

The measures were realized according to the following roadmap, as illustrated in
Figure \ref{fig:dispExp}.

% \begin{itemize}
% \item A estação $E_D$ envia pacotes Ethernet para a placa $eth_0$ da estação $E_M$,
%   provocando interrupções assíncronas em relação às aplicações executando em $E_M$.
% \item A interrupção associada à chegada de um pacote provoca a preempção da
%   aplicação em execução no processador pelo tratador de interrupção $T_{eth_0}$.
% \item O tratador $T_{eth_0}$ foi restrito ao seu mínimo: ele apenas escreve no pino
%   de interrupção da PP e armazena o instante $t_1$ na memória. Este instante
%   corresponde, portanto, ao valor lido no relógio local, no instante na escrita da
%   PP, logo após a chegada de uma pacote Ethernet.
% \item A requisição de interrupção associada à escrita no pino de interrupção da PP
%   provoca a preempção da aplicação em execução no processador pelo tratador de
%   interrupção $T_{PP}$.
% \item $T_{PP}$ grava o instante $t_2$ e acorda a tarefa $\tau$. Este valor $t_2$
%   corresponde ao valor do relógio local, logo após o início de $T_{PP}$.
% \item No momento que a tarefa $\tau$ acorda, ela grava o instante $t_3$ e volta a
%   ficar suspensa até a próxima interrupção na PP.  Portanto, $t_3$ corresponde ao
%   tempo no qual a tarefa $\tau$ começa a executar, no final da cascata de eventos
%   provocada pela chegada de um pacote na placa de rede.
% \end{itemize}

\begin{itemize}
\item The $E_T$ station sends Ethernet frame to the $eth_0$ device of the $E_M$
  station, causing interrupt asynchronously in regard to applications executing on $E_M$.
\item The interruption associated with the arrival of a package causes preemption of
  the application executing on the processor by the interrupt handler ($T_{eth_0}$)
  of the network device $eth_0$.
\item The interrupt handler ($T_{eth_0}$) is reduced to its minimum: it only sets
  the Parallel Port Interrupt Request (PP-IRQ) line and stores the instant $t_1$ in
  memory. Hence, $t_1$ is the value read on the $E_M$ local clock at the setting
  instant of the PP-IRQ line, just after the arrival of an Ethernet frame.
\item The interrupt request associated with the setting of the PP-IRQ line 
  causes the preemption of the application running on the processor by
  the PP interrupt handler $T_{PP}$.
\item $T_{PP}$ records the instant $t_2$ and wakes up task $\tau$. This
  second instant $t_2$ corresponds to the value of the $E_M$ local clock, just after the start
  of $T_{PP}$.
\item When that task $\tau$ wakes up, it records the instant $t_3$ and is suspended
  until the next PP interruption. So, $ t_3 $ is the instant when task $\tau$ begins
  to execute at the end of the cascade of events caused by the arrival of a package in
  the network card.
\end{itemize}

% Como representado na Figura \ref{fig:dispExp}, $Lat_{irq}$ corresponde à diferença
% $t_2 - t_1$ e $Lat_{ativ}$ a diferença $t_3 - t_2$. No decorrer do experimento, a
% transferência das medições da memória para o sistema de arquivos foi realizada por
% um canal FIFO lido por um processo usuário de forma a impedir qualquer interferência
% entre a aquisição dos dados e seu armazenamento no sistema de arquivos. Além da
% prioridade deste processo ser menor que as demais tarefas e tratadores de
% interrupções executados em modo \ing{kernel}, os eventos de transferências de dados
% eram suficientemente raros (20 por segundo) para não interferir nas medidas
% realizadas.

As depicted in Figure \ref{fig:dispExp}, $Lat_{irq}$ corresponds to the
difference $t_2 - t_1$ and $Lat_{ativ}$ to the difference $t_3 - t_2$. During the
experiment, the transfer of measurements of memory to the file system was performed
by a FIFO channel read by a user process in order to prevent any interference
between the data acquisition and its storage in the file system. Such isolation was
guaranteed by two facts: first the priority of the user process was smaller than the
priority of interrupts handlers executed in \kernell mode and second,  data
transfers were sufficiently rare events (20 per second) not to interfere in the measures
realized.

\begin{figure*}[t!]
  \centering {\scalebox{1}{\input{fig/dispExp2.pstex_t}}}
  \caption{Interrupt and activation latencies measurement at station $E_M$}
  \label{fig:dispExp2}
\end{figure*}

One of the main drawbacks of the experimental setting describes in this Section
is that measurements are realized by the station which is trigerred. To do so, station
$E_M$ waits for the asynchronous arrival of an Ethernet frame at $eth_0$ to
launch the cascade events which leads to local measurements. The consequence 
of such approach is that the parallel port interrupt is always requested on behalf
of the $eth_0$ interrupt handler, thus compromising the validity of the interrupt
latency measure. In order to avaliate the impact of such bias, a second experiment
was implemented, following suggestion of a revisor of a previous version of this
work.

\subsection{Second experimental configuration}
\label{sec:exp2}

\begin{figure}[htb]
  \centering {\scalebox{1}{\input{fig/config2.pstex_t}}}
  \caption{Second experimental configuration}
  \label{fig:config2}
\end{figure}

The second experiment use the same three stations, but, while station $E_L$ remains
configured as before, stations $E_T$ and $E_M$ were used in different modes, as
illustrated by Figure \ref{fig:config2}:

\begin{enumerate}
\item The triggering station $E_T$ is now connected to the $E_M$ station via 
the parallel port and directly triggers PP interrupt request at a fixed frequency of $20 Hz$;
\item The measurement station $E_M$ handles the PP-IRQ and wakes up the real time
  task $\tau$ which is waiting for external events;
\end{enumerate}

In this new configuration, time measurements were not be realized at $E_M$, because
the instant of the initial PP-IRQ was not known by $E_M$, unless clocks would be
synchronized.  To avoid the need for such synchronization, time measurements were
only carried by $E_T$.  To do so, the parallel port was used by $E_M$ to trigger an
interrupt request at $E_T$, as illustrated in Figure \ref{fig:dispExp2}. Whenever
such request happened, the PP-IRQ handler of $E_T$ stored the value of the TSC. Such
approach increased the timestamp value of the interrupt event produced by $E_M$ by
the interrupt latency of station $E_T$. However, as this station used
Linux$^{\mathbf{Xen}}$ and was running in single mode with minimal load, this extra
latency, denoted $\delta$ in Figure \ref{fig:dispExp2}, was bounded and
deterministic. An estimate of $\delta$ can be deduced dividing the total latency
obtained with $E_M$ using Linux$^{\mathbf{Xen}}$ with minimal load. Such estimates
gives $\delta \approx 9 \mu s$. Using this value, the desired measurements of $Lat_{irq}$
and $Lat_{ative}$ can be deduced with a good accuracy.

The measures were realized according to the following roadmap, as illustrated in
Figure \ref{fig:dispExp2}.

\begin{itemize}
\item The $E_T$ station triggers an interrupt request on the PP-IRQ line of station
  $E_M$ and stores the instant $t_1$ in memory. Hence, $t_1$ is the value read on
  the $E_T$ local clock at the setting instant of the PP-IRQ line.
\item The interrupt request triggered on the PP-IRQ line of station $E_M$ 
  causes the preemption of the application running on the $E_M$ processor by
  the PP interrupt handler $T_{PP}(E_M)$.
\item $T_{PP}(E_M)$ triggers an interrupt request on the PP-IRQ line of station
  $E_T$ and wakes up task $\tau$. 
\item The interrupt request triggered on the PP-IRQ line of station $E_T$ causes the
  execution of the PP interrupt handler ($T_{PP}(E_T)$) which stores the $t_2$
  instant value. This second instant $t_2$ corresponds to the value of the $E_T$
  local clock, just after the start of $T_{PP}(E_T)$.
\item When that task $\tau$ wakes up, it triggers an interrupt request on the PP-IRQ
  line of station $E_T$.
\item Finally, the interrupt request triggered on the PP-IRQ line of station $E_T$
  causes the execution of the PP interrupt handler ($T_{PP}(E_T)$) which stores the
  $t_3$ instant value. So, $ t_3 $ is the instant when task $\tau$ begins to execute
  increased by the $E_T$ interrupt latency.
\end{itemize}

As depicted in Figure \ref{fig:dispExp2}, $Lat_{irq}$ corresponds to the difference
$t_2 - t_1 - \delta$ and $Lat_{ativ}$ to the difference $t_3 - t_2 - \delta$. 

As in the first experiment, the transfer of measurements of memory to the $E_T$ file
system was performed by a FIFO channel read by a user process in order to prevent
any interference between the data acquisition and its storage in the file system.

\subsection{I/O, processing and interrupt loads}
\label{sec:carga}

% Num primeiro momento, realizou-se experimentos com uma carga mínima no processador
% da estação $E_M$ (modo \ing{single}). Desta forma, observou-se o comportamento
% temporal das três plataformas em situação favorável.  Em seguida, dois tipos de
% cargas foram utilizados simultaneamente para sobrecarregar $E_M$. Tais sobrecargas
% tiveram por objetivo avaliar a capacidade de cada plataforma em garantir uma
% latência determinística no tratamento das interrupções e na ativação de tarefas de
% tempo real, apesar da existência de outras atividades não-críticas.  As cargas de
% I/O e processamento foram realizadas executando as instruções seguintes na estação
% $E_M$:

Initially, we realized experiments with a minimum load on the processor of
the $E_M$ station (\kernell mode single). Thus, the temporal behavior of the three
platforms in favourable situation was observed. Then, two different types of loads
were used simultaneously to overload the $E_M$ station. Such overloads were meant to
assess the capability of each platform to ensure deterministic latencies in the
treatment of interruptions and activation of real-time tasks, despite the
existence of other non-critical activities. The loads of I/O and processing were
realized executing the following instructions at $E_M$ station:

%\begin{table}[h]
%\caption{Processor load instruction set}
%\vspace{ 4pt }
% \setstretch{0.94}
\begin{center}
  \framebox[0.47\textwidth]{%
    \begin{minipage}{0.84\linewidth}
      \vspace{ 4pt } \scriptsize{%
        \texttt{while "true"; do\\
          \rule{0.3cm}{0pt} dd if=/dev/hda2 of=/dev/null bs=1M count=1000\\
          \rule{0.3cm}{0pt} find / -name "*.c" | xargs egrep include\\
          \rule{0.3cm}{0pt} tar -cjf /tmp/root.tbz2 /usr/src/linux-xenomai\\
          \rule{0.3cm}{0pt}  cd /usr/src/linux-preempt; make clean; make\\
          done \vspace{ 3pt } %\nolinebreak %\raisebox{10mm}{\rule{0cm}{0.01cm}}
        }}
    \end{minipage}
  }
\end{center}
%\end{table}
%\vspace{ 4pt }

% \setstretch{1}

% Um outro estresse de interrupção foi criado utilizando uma comunicação UDP entre a
% estação $E_M$ configurada como servidor e a estação $E_C$ configurada como
% cliente. Para isolar esta comunicação da comunicação entre $E_M$ e $E_D$,
% utilizou-se a segunda placa de rede $eth_1$ de $E_M$, assim com ilustrado pelo
% diagrama da Figura \ref{fig:dispExp}.  Durante o experimento, o processo cliente
% hospedado pela estação $E_C$ transmitiu pequenos pacotes de 64 \ing{bytes} na
% freqüência máxima permitida pela rede, ou seja, com uma freqüência superior a $200
% kHz$ (um pacote a cada $10 \mu s$).  Desta forma, mais de 100.000 interrupções por
% segundo foram geradas pela placa $eth_1$ de $E_M$. A placa $eth1$ foi registrada na
% linha de interrupção 18 de $E_M$, cuja prioridade é menor que a prioridade da porta
% paralela. Nos experimentos com cargas, os dois tipos de estresses foram aplicados
% simultaneamente e as medições só foram iniciadas alguns segundos depois.

Another stress of interruption was created using a UDP communication between the
$E_M$ station configured as a server and the $Load$ station configured as a
client. To isolate the communication between the $E_M$ and $Load$ stations, the
second network device ($eth_1$) of the $E_M$ station has been used, as well as
illustrated by Figure \ref{fig:dispExp}. During the experiment, the process client
hosted by the $Load$ station sent small packages of 64 bytes at the maximum
frequency ($200 kHz$) allowed by the bandwidth network. Thus, more than $100,000$ per
second interruptions were generated at the $eth_1$ $E_M$ card. This device made
use of the $E_M$ IRQ line $18$, whose priority is lower than the priority of the
PP-IRQ line. Such a low priority was choosen in order to test the efficiency of the sudied
platform, as one should expect that latencies would not be affected by the load.

 In experiments with overload, the two types of loads were applied
simultaneously and the measurements were only started a few seconds later.
% É interessante observar que a interrupção na porta paralela sempre acontece logo
% após a execução de $T_{eth}$. Portanto, a medida da latência de interrupção foi
% estimada como sendo $t_2 - t_1$.  Esta estimativa deve ser considerada apenas como
% indicativa, mas suficiente para ilustrar o determinismo das plataformas em estudo;

% Como foi visto na Seção \ref{sec:latAtiv}, a latência de ativação ($t_3- t_2$)
% caracteriza o tempo necessário para ativar uma tarefa após a ocorrência do seu
% evento de disparo.  O dispositivo apresentado aqui permitiu obter medidas
% quantitativamente corretas desta latência.  Além disso, o efeito do aumento da
% atividade na estação de medição pôde ser investigado, pois o instante de disparo
% da interrupção na porta paralela era totalmente independente da atividade dos
% processos na estação de medição.


\section{Linux$^{\mathbf{Prt}}$ and Linux$^{\mathbf{Xen}}$
  assessment}
\label{cap:platEstud}

\subsection{Configuration}

% Os experimentos foram realizados em computadores Pentium 4 com processadores de 2.6
% GHz e 512 Mb de memória, com o objetivo de ilustrar o comportamento temporal das
% três plataformas seguintes:

The experiments were conducted on three Pentium 4 computers with $2.6 GHz$
processors and $512 MB$ RAM memory, in order to illustrate the temporal behavior of
the three following platforms:

\begin{description}
\item[$\bullet \;$ Linux$^{\mathbf{Std}}$:] Linux standard - \kernell version 2.6.23.9
  (\ing{low-latency} option);
\item[$\bullet \;$ Linux$^{\mathbf{Prt}}$:] Linux with \ing{patch}
  \preemptt (rt12) - \kernell version 2.6.23.9;
\item[$\bullet \;$ Linux$^{\mathbf{Xen}}$:] Linux with \ing{patch} Xenomai - version
  2.4-rc5 - \kernell version 2.6.19.7.
\end{description}

% Utilizou-se a configuração Linux$^{\mathbf{Std}}$ para realizar experimentos de
% referência para efeito de comparação com as duas plataformas de tempo real
% Linux$^{\mathbf{Prt}}$ e Linux$^{\mathbf{Xen}}$.  A versão estável do \kernell
% 2.6.23.9, disponibilizada em dezembro de 2007 foi escolhida para o estudo de
% Linux$^{\mathbf{Prt}}$, pois este \ing{patch} tem evoluído rapidamente desde sua
% primeira versão publicada há dois anos.  No entanto, utilizou-se a versão do
% \kernell 2.6.19.7 para o estudo da versão 2.4-rc5 de Xenomai. De fato, considerou-se
% desnecessário atualizar a versão do \kernel, pois Xenomai é baseado no Adeos (ver
% Seção \ref{sec:xenomai}) e, portanto, as garantias temporais oferecidas para as
% aplicações executando no primeiro domínio dependem apenas da versão do Xenomai e do
% \ing{patch} Adeos associado, e não, da versão do \kernell Linux.

The Linux$^{\mathbf{Std}}$ configuration was used to perform reference experiments
in order to allow for the comparison with the two real-time platforms
Linux$^{\mathbf{Prt}}$ and Linux$^{\mathbf{Xen}}$.  The stable version of \kernell
2.6.23.9, released in December 2007, was chosen for the study of
Linux$^{\mathbf{Prt}}$ because this patch has evolved rapidly since its first stable
version released two years ago. However, the \kernell version of 2.6.19.7 was used
for the study of version 2.4-rc5 of Xenomai. In fact, it was considered unnecessary
to upgrade the \kernel version because Xenomai is based on Adeos (see Section
\ref{sec:xenomai}) and therefore, the temporal guarantees offered to applications
executing in the first domain only depend on the Xenomai version and its associated
patch Adeos, and not on the Linux \kernell version.

% As medidas das latências de interrupção e de ativação foram realizadas pela consulta
% do \ing{Time Stamp Counter} (TSC), permitindo uma precisão abaixo de $30 ns$ (88
% ciclos), verificada experimentalmente.  Utilizou-se uma freqüência de disparo dos
% eventos pela estação $E_D$ de 20Hz.  Para cada plataforma, dois experimentos de 10
% minutos foram realizados. O primeiro sem carga nenhuma do sistema e o segundo
% aplicando os estresses apresentados na Seção \ref{sec:carga}.

The interrupt and activation latency measurements were made by reading the Time
Stamp Counter (TSC), allowing a precision of less than $30 ns$ (88 cycles),
experimentally verified. In both experiments, a $20Hz$ frequency was used by station
$E_T$ to trigger events at station $E_M$. For each platform and configuration, two
experiments were conducted of 10 minutes each. The first was carried on without any
load of the system and the second was carried on applying the loads presented in
Section \ref{sec:carga}.

%  \col{Para a plataforma Linux$^{\mathbf{Xen}}$, apesar do experimento com
% estresses ter sido repetido por uma duração de 12 horas, os resultados confirmaram
% os resultados obtidos com duração de 10 minutos}.


% Para as duas plataformas RTAI e Xenomai, os diferentes testes de latências
% fornecidos foram utilizados, dando resultados menores que $10 \mu s$ no pior caso
% para a latência de interrupção, conforme os padrões da arquitetura Intel Pentium
% 4. Em ambas plataformas, desabilitou-se as interrupções de gerenciamento do
% sistema (\ing{SMI}), conforme as recomendações dos desenvolvedores \cite{RTAI,
%   Xenomai}. Isto cancelou uma latência periódica (a cada 32 segundos) de
% aproximadamente $2.5ms$ que aparecia nos testes.  No caso das plataforma Lx19
% Linux$^{\mathbf{Std}}$ e Linux$^{\mathbf{Prt}}$, estas interrupções foram também
% desabilitadas, porém, não foi constatado nenhuma alteração das medidas realizadas.
% as interrupções de gerenciamento do sistema não foram desabilitadas.  No entanto,
% pelo fato das interrupções \ing{SMI} ter um período de 32 segundos, este fato não
% alterou os resultados experimentais de forma significativa.  No entanto, não se
% observou nenhuma latência da ordem de $2.5ms$ nos experimentos relativos a estas
% duas plataformas. Provavelmente, porque a interrupção periódica de SMI aconteceu
% num intervalo de tempo sem medida.


% Observar que RT-Linux, RTAI e Xenomai adotam soluções tecnológicas parecidas,
% baseadas em \ing{nanokernel}. Portanto, o estudo comparativo foi realizado apenas
% com a plataforma Xenomai.

Experimental results are presented through Figures
in which the horizontal axis represents the instant of observation
ranging from 0 to 60 seconds and the vertical axis represents the latencies measures
in $\mu s$ (such values should be multiplied by $2.6 10^3$ to obtain the number of
TSC cycles). Although each experiment was run for ten minutes, Figures are presented
for a range of $60s$, as such interval is sufficient to observe the pattern of
behavior of each platform. During this one minute interval, the total number of
events is 1200, as the arrival frequency of Ethernet frame at the $eth_0$
network device of station $E_M$ is $20 Hz$.

Below each figure, the following values are given: Mean (Mean), Standard Deviation
(SD), minimum (Mn) and maximum (Mx). These numbers were obtained considering
the duration of ten minutes of each experiment. As much as possible, the same
vertical scale was used for all graphics. As a result, high values may have layed
outside the graphics. Such occurrences was represented by a triangle near the maximum
value of the vertical axis.

\subsection{First configuration experimental results}
\label{sec:resExp}

% Os resultados experimentais são apresentados nas Figuras \ref{fig:latIrq} e
% \ref{fig:latAtiv}, onde o eixo horizontal representa o instante de observação
% variando de 0 a 60 segundos e o eixo vertical representa as latências medidas em
% $\mu s$ (tais valores podem ser multiplicados por $2.6 10^3$ para obter o número de
% ciclos do TSC).  Apesar de cada experimento ter durado no mínimo uma hora,
% escolheu-se apresentar apenas resultados para um intervalo de $60s$, pois este
% intervalo é suficiente para observar o padrão de comportamento de cada
% plataforma. Neste intervalo, o total de eventos por experimentos é 1200, pois a
% freqüência de chegada de pacotes utilizada foi de $20 Hz$.

The experimental results for the first configuration (see Section \ref{sec:exp1})
are shown in Figure \ref{fig:latIrq} and\ref{fig:latAtiv}.
		
% Abaixo de cada Figura, os seguintes valores são indicados: Valor Médio (VM), desvio
% padrão (DP), valor mínimo (Min) e valor máximo (Max). Estes valores foram obtidos
% considerando a duração de uma hora de cada experimento. Na medida do possível,
% utilizou-se a mesma escala vertical para todos os gráficos.  Conseqüentemente,
% alguns valores altos podem ter ficado fora das Figuras. Tal ocorrência foi
% representada por um triângulo próximo do valor máximo do eixo vertical.


\subsubsection{Interrupt latencies}
\label{sec:latIrq}

\begin{figure*}%
  \centering
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - without load} \newline
  \vskip 1mm M:     8.9, SD:     0.3,  Mn:     8.7, Mx:    18.4 }]{%
    \label{fig:ker23Sem}%
    {\scalebox{0.58}{\input{fig/ker23Sem}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - with loads} \newline
  \vskip 1mm M:    10.4, SD:     1.9,  Mn:     8.8, Mx:    67.7 }]{%
    \label{fig:ker23Tot}%
    {\scalebox{0.58}{\input{fig/ker23Tot}}}}%

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load} \newline
  \vskip 1mm M: 21.5, SD: 1.7, Mn: 20.3, Mx: 45.1 }]{%
    \label{fig:preSem}%
    {\scalebox{0.58}{\input{fig/preSem}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads} \newline
  \vskip 1mm M: 58.5, SD: 26.4, Mn: 17.2, Mx: 245.9}]{%
    \label{fig:preTot}%
    {\scalebox{0.58}{\input{fig/preTot}}}}%

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load, option
      \cod{IRQF\_NODELAY}} \newline
    \vskip 1mm M: 8.9, SD: 0.2, Mn: 8.8, Mx: 16.7}]{%
    \label{fig:preSemSchedND}%
    {\scalebox{0.58}{\input{fig/preSemND}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads, option
      \cod{IRQF\_NODELAY}} \newline
    \vskip 1mm M: 10.6, SD: 1.6, Mn: 8.9, Mx: 35.8}]{%
    \label{fig:preTotSchedND}%
    {\scalebox{0.58}{\input{fig/preTotND}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - without load} \newline
  \vskip 1mm M: 9.0, SD: 0.1, Mn: 8.8, Mx: 11.1}]{%
    \label{fig:xenSem}%
    {\scalebox{0.58}{\input{fig/xenSem}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - with loads} \newline
  \vskip 1mm M: 10.2, SD: 0.1, Mn: 8.8, Mx: 20.8}]{%
    \label{fig:xenTot}%
    {\scalebox{0.58}{\input{fig/xenTot}}}}%

  \caption[Interrupt latencies]{Interrupt latencies with PP-IRQ triggered by the
    $eth_0$ interrupt handler with a $20 Hz$ frequency.}
  \label{fig:latIrq}%
\end{figure*}

% A Figura \ref{fig:latIrq} apresenta as latências de interrupção medidas, com e sem
% estresse do sistema.  Como pode ser observado, sem carga, o Linux$^{\mathbf{Std}}$ e
% o Linux$^{\mathbf{Xen}}$ tem comportamentos parecidos. Com carga, observa-se uma
% variação significativa do Linux$^{\mathbf{Std}}$, como esperado.

Figure \ref{fig:latIrq} shows the interrupt latencies measured, with and without
load of the system. As can be seen, without load, Linux$^{\mathbf{Std}}$ and
Linux$^{\mathbf{Xen}}$ has similar behaviour. With loads, there is a significant
variation of Linux$^{\mathbf{Std}}$, as expected.

% Com relação ao Linux$^{\mathbf{Prt}}$, dois resultados chamam atenção. Primeiro, o
% comportamento do sistema sem carga exibe latências da ordem de 20 $\mu s$. Isto é
% causado pela implementação dos \ing{threads} de interrupção vista na Seção
% \ref{sec:preemptRT}.  Segundo, contradizendo as expectativas, a aplicação do
% estresses teve um impacto significativo, provocando uma alta variabilidade das
% latências. De fato, entre o instante no qual o tratador $T_{PP}$ requer a
% interrupção do processador e o instante no qual este \ing{thread} acorda
% efetivamente, uma ou várias interrupções podem ocorrer.  Neste caso, a execução dos
% tratadores associados pode provocar o atraso da execução de $T_{PP}$.

With respect to Linux$^{\mathbf{Prt}}$, two results draw attention. First, in
absence of load, the system displays latencies of around $20 \mu s$. This is due to
the threaded implementation of interruption seen in Section \ref{sec:preemptRT}.
Second, contradicting the expectations, the application of load had a significant
impact, causing a high variability of latency. In fact, between the instant in which
the $T_{PP}$ handler requires the interruption of the processor and the instant in
which the IRQ thread actually wakes up, one or more interruptions may occur. In such
a case, the execution of the associated handlers may delay the execution of
$T_{PP}$.
 
% Para cancelar esta variabilidade indesejável, é possível usar o
% Linux$^{\mathbf{Prt}}$ sem utilizar a implementação de \ing{threads} de
% interrupção. Para tanto, usa-se a opção \cod{IRQF\_NODELAY} na requisição inicial da
% linha de interrupção. Utilizando esta opção na definição da linha de interrupção da
% porta paralela, o comportamento do Linux$^{\mathbf{Prt}}$ passa a ser semelhante ao
% Linux$^{\mathbf{Std}}$.

To cancel this undesirable variability, one can use Linux$^{\mathbf{Prt}}$ without
using the implementation of threads of interruption. For this, one use the option
\cod{IRQF\_NODELAY} at initialization time of the IRQ line. As can be observed,
using this option in requesting the PP-IRQ line, the behavior of
Linux$^{\mathbf{Prt}}$ turns to be similar to Linux$^{\mathbf{Std}}$.

\subsubsection{Activation latencies}

% A Figura \ref{fig:latAtiv} apresenta os resultados para as latências de ativação sem
% estresse e com estresse do processador.  Como pode ser observado, o comportamento de
% Linux$^{\mathbf{Std}}$ é inadequado para atender os requisitos de tempo
% real. Linux$^{\mathbf{Prt}}$ e Linux$^{\mathbf{Xen}}$, por outro lado, apresentam
% valores de latências dentro dos padrões esperados.  Vale a pena notar o
% comportamento destes sistemas com carga.  Apesar do valor médio encontrado para
% Linux$^{\mathbf{Xen}}$ ($8,7 \mu s$) ser superior ao do Linux$^{\mathbf{Prt}}$ ($3,8
% \mu s$), o desvio padrão é significativamente menor em favor de
% Linux$^{\mathbf{Xen}}$, característica desejável nos sistemas de tempo real
% críticos. De fato, para tais sistemas, deseja-se que o pior caso seja próximo do
% caso médio.

Figure \ref{fig:latAtiv} shows the results for the activation latencies without and
with load of the processor. As can be seen, the behavior of Linux$^{\mathbf{Std}}$
is inadequate to meet the real-time requirements. On the other hand,
Linux$^{\mathbf{Prt}}$ and Linux$^{\mathbf{Xen}}$ have values of latencies within
the expected standard. It is worth noting the behavior of these systems with
load. Although the average value found for Linux$^{\mathbf{Xen}}$ ($8,7 \mu s$) is
superior to the Linux$^{\mathbf{Prt}}$ ($3,8 \mu s$), the standard deviation is
significantly lower in favor of Linux$^{\mathbf{Xen}}$, desirable feature in
real-time critical systems. In fact, for such systems, hopes that the worst case is
close to the average case.
	
\begin{figure*}%
  \centering
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - without load} \newline
  \vskip 1mm M:     4.6, SD:     0.4,  Mn:     4.4, Mx:    16.2}]{%
    \label{fig:ker23SemSched}%
    {\scalebox{0.58}{\input{fig/ker23SemSched}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - with loads}\newline
  \vskip 1mm M:    37.3, SD:    48.2,  Mn:     4.6, Mx:   617.5}]{%
    \label{fig:ker23TotSched}%
    {\scalebox{0.58}{\input{fig/ker23TotSched}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load} \newline
  \vskip 1mm M: 2.1, SD: 0.2, Mn: 1.2, Mx: 9.4}]{%
    \label{fig:preSemSched}%
    {\scalebox{0.58}{\input{fig/preSemSched}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads} \newline
  \vskip 1mm M: 3.8, SD: 2.8, Mn: 1.1, Mx: 27.4}]{%
    \label{fig:preTotSched}%
    {\scalebox{0.58}{\input{fig/preTotSched}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load, option
      \cod{IRQF\_NODELAY}} \newline
  \vskip 1mm M:     5.3, SD:     0.3,  Mn:     5.0, Mx:    13.1}]{%
    \label{fig:preSemSchedND}%
    {\scalebox{0.58}{\input{fig/preSemSchedND}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads, option
      \cod{IRQF\_NODELAY}} \newline
  \vskip 1mm M:     8.0, SD:     2.0,  Mn:     5.2, Mx:    31.0}]{%
    \label{fig:preTotSchedND}%
    {\scalebox{0.58}{\input{fig/preTotSchedND}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - without load} \newline
  \vskip 1mm M: 2.1, SD: 0.5, Mn: 1.8, Mx: 8.4}]{%
    \label{fig:xenSemSched}%
    {\scalebox{0.58}{\input{fig/xenSemSched}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - with loads} \newline
  \vskip 1mm M: 8.7, SD: 0.3, Mn: 1.8, Mx: 18.7}]{%
    \label{fig:xenTotSched}%
    {\scalebox{0.58}{\input{fig/xenTotSched}}}}

  \caption[]{Activation latencies with PP-IRQ triggered by the
    $eth_0$ interrupt handler with a $20 Hz$ frequency.}
  \label{fig:latAtiv}%
\end{figure*}

% É interessante ainda comparar o comportamento de Linux$^{\mathbf{Prt}}$ sem utilizar
% o contexto de \ing{threads} de interrupção, isto é, com a opção \cod{IRQF\_NODELAY},
% comentada anteriormente. Como pode ser observado na Figura \ref{fig:latAtivND},
% apesar das latências de ativação sem estresse apresentar bons resultados em
% comparação ao Linux$^{\mathbf{Prt}}$, seus valores com estresse indicam um
% comportamento menos previsível que o Linux$^{\mathbf{Xen}}$.

It is also interesting to compare the behavior of Linux$^{\mathbf{Prt}}$ without
using the implementation of interuption thread , that is, with the option
\cod{IRQF\_NODELAY}, commented earlier. As can be seen in Figure\ref{fig:latAtiv},
despite the latencies of activation without load apresenting good results in comparison to
Linux$^{\mathbf{Prt}}$, its values with load indicate a slightly less predictable
behavior than Linux$^{\mathbf{Xen}}$.

% \begin{figure*}%
%   \centering
%   \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load} \newline
%   \vskip 1mm M:     5.3, SD:     0.3,  Mn:     5.0, Mx:    13.1}]{%
%     \label{fig:preSemSchedND}%
%     {\scalebox{0.58}{\input{fig/preSemSchedND}}}} \hspace{44pt}%
%   \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads} \newline
%   \vskip 1mm M:     8.0, SD:     2.0,  Mn:     5.2, Mx:    31.0}]{%
%     \label{fig:preTotSchedND}%
%     {\scalebox{0.58}{\input{fig/preTotSchedND}}}}

%   \caption[]{Activation latency of Linux$^{\mathbf{Prt}}$
%     without interruption threading  (option \cod{IRQF\_NODELAY}).}
%   \label{fig:latAtivND}%
% \end{figure*}

% \begin{figure}%
%   \centering
%   \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load} \newline
%   \vskip 1mm M:     8.9, SD:     0.2,  Mn:     8.8, Mx:    16.7}]{%
%     \label{fig:preSemSchedND}%
%     {\scalebox{0.58}{\input{fig/preSemND}}}}
%   \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads} \newline
%   \vskip 1mm M:     10.6, SD:     1.6,  Mn:     8.9, Mx:    35.8}]{%
%     \label{fig:preTotSchedND}%
%     {\scalebox{0.58}{\input{fig/preTotND}}}}

%   \caption[]{Latência de interrupção do Linux$^{\mathbf{Prt}}$
%     desabilitando o \ing{thread} associado as interrupções da
%     PP (opção \cod{IRQF\_NODELAY}).}
%   \label{fig:latAtivND}%
% \end{figure}


\subsection{Second configuration experimental results}
\label{sec:resExp}

The experimental results for the second experimental configuration (see Section
\ref{sec:exp2}) are shown in Figure \ref{fig:latIrq2} and \ref{fig:latAtiv2}.

\subsubsection{Interrupt latencies}
\label{sec:latIrq}

\begin{figure*}%
  \centering
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - without load} \newline
  \vskip 1mm M:    18.0, SD:     0.3,  Mn:     9.6, Mx:    27.3 }]{%
    \label{fig:ker23Sem}%
    {\scalebox{0.58}{\input{fig2/ker23Sem}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - with loads} \newline
  \vskip 1mm M:    21.8, SD:     3.2,  Mn:     9.8, Mx:    80.6 }]{%
    \label{fig:ker23Tot}%
    {\scalebox{0.58}{\input{fig2/ker23Tot}}}}%

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load} \newline
  \vskip 1mm M:    19.4, SD:     0.5,  Mn:     9.8, Mx:    42.2 }]{%
    \label{fig:preSem}%
    {\scalebox{0.58}{\input{fig2/preSem}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads} \newline
  \vskip 1mm M:    41.9, SD:    18.9,  Mn:     9.7, Mx:   324.4 }]{%
    \label{fig:preTot}%
    {\scalebox{0.58}{\input{fig2/preTot}}}}%

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load, option
      \cod{IRQF\_NODELAY}} \newline
    \vskip 1mm M:    18.1, SD:     0.3,  Mn:     9.1, Mx:    25.5 }]{%
    \label{fig:preSemSchedND}%
    {\scalebox{0.58}{\input{fig2/preSemND}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads, option
      \cod{IRQF\_NODELAY}} \newline
    \vskip 1mm M:    21.2, SD:     2.4,  Mn:     9.1, Mx:    50.5  }]{%
    \label{fig:preTotSchedND}%
    {\scalebox{0.58}{\input{fig2/preTotND}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - without load} \newline
  \vskip 1mm M:    18.2, SD:     0.3,  Mn:     9.1, Mx:    23.1 }]{%
    \label{fig:xenSem}%
    {\scalebox{0.58}{\input{fig2/xenSem}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - with loads} \newline
  \vskip 1mm M:    20.7, SD:     1.5,  Mn:     9.1, Mx:    30.0 }]{%
    \label{fig:xenTot}%
    {\scalebox{0.58}{\input{fig2/xenTot}}}}%

  \caption[Interrupt latencies]{Interrupt latencies with PP-IRQ triggered on $E_M$
    by $E_T$ at a $20 Hz$ frequency.}
  \label{fig:latIrq2}%
\end{figure*}

% A Figura \ref{fig:latIrq} apresenta as latências de interrupção medidas, com e sem
% estresse do sistema.  Como pode ser observado, sem carga, o Linux$^{\mathbf{Std}}$ e
% o Linux$^{\mathbf{Xen}}$ tem comportamentos parecidos. Com carga, observa-se uma
% variação significativa do Linux$^{\mathbf{Std}}$, como esperado.

Figure \ref{fig:latIrq2} shows the interrupt latencies measured, with and without
load of the system.  As expected, an extra latency of $9$ to $10 \mu s$ is observed
for the interrupt latencies measurements of all platforms. As explained in Section
\ref{sec:exp2}, this extra latency corresponds to the interrupt latency of $E_T$
which was denoted $\delta$ in Figure \ref{fig:dispExp2}.

The only other noticeable difference is related to Linux $^{\mathbf{Prt}}$ whose
interrupt latencies values are somehow smaller in the second experiments. However,
this is due to the thread implementation, which reacts faster to an hardware
interrupt request than to a software interrupt request. As in the first experiment,
using the option \cod{IRQF\_NODELAY} to disable the parallel port IRQ threading, the
behavior of Linux$^{\mathbf{Prt}}$ turns to be similar to Linux$^{\mathbf{Std}}$.

As a first conclusion, we emphasize that results obtained with the second
configuration are similar to those obtained with the first experimental
configuration, thus motivating the use of the first experiment configuration for
future comparison works.

\subsubsection{Activation latencies}

\begin{figure*}%
  \centering
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - without load} \newline
  \vskip 1mm M:     5.7, SD:     0.6,  Mn:     5.0, Mx:    15.6 }]{%
    \label{fig:ker23SemSched}%
    {\scalebox{0.58}{\input{fig2/ker23SemSched}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Std}}$ - with loads}\newline
  \vskip 1mm M:    23.3, SD:    28.5,  Mn:     5.0, Mx:   623.3 }]{%
    \label{fig:ker23TotSched}%
    {\scalebox{0.58}{\input{fig2/ker23TotSched}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load} \newline
  \vskip 1mm M:     6.1, SD:     0.6,  Mn:     5.0, Mx:    17.3 }]{%
    \label{fig:preSemSched}%
    {\scalebox{0.58}{\input{fig2/preSemSched}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads} \newline
  \vskip 1mm M:    10.1, SD:     3.7,  Mn:     5.0, Mx:    70.5 }]{%
    \label{fig:preTotSched}%
    {\scalebox{0.58}{\input{fig2/preTotSched}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - without load, option
      \cod{IRQF\_NODELAY}} \newline
  \vskip 1mm M:     6.8, SD:     0.4,  Mn:     5.1, Mx:    15.4 }]{%
    \label{fig:preSemSchedND}%
    {\scalebox{0.58}{\input{fig2/preSemSchedND}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Prt}}$ - with loads, option
      \cod{IRQF\_NODELAY}} \newline
  \vskip 1mm M:    15.6, SD:     6.6,  Mn:     5.0, Mx:   107.2}]{%
    \label{fig:preTotSchedND}%
    {\scalebox{0.58}{\input{fig2/preTotSchedND}}}}

  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - without load} \newline
  \vskip 1mm M:     6.5, SD:     0.5,  Mn:     5.0, Mx:    13.2 }]{%
    \label{fig:xenSemSched}%
    {\scalebox{0.58}{\input{fig2/xenSemSched}}}} \hspace{44pt}%
  \subfloat[\small{\textbf{Linux$^{\mathbf{Xen}}$ - with loads} \newline
  \vskip 1mm M:    11.1, SD:     3.0,  Mn:     5.0, Mx:    25.7 }]{%
    \label{fig:xenTotSched}%
    {\scalebox{0.58}{\input{fig2/xenTotSched}}}}

  \caption[Activation latencies]{Activation latencies with PP-IRQ triggered on $E_M$
    by $E_T$ at a $20 Hz$ frequency.}
  \label{fig:latAtiv2}%
\end{figure*}


Figure \ref{fig:latAtiv2} shows the activation latencies measured, with and without
load of the system. 

Somehow surprisingly, the $\delta$ extra latency observed in the interrupt latencies
measurements is much smaller ($\delta \approx 2.5 \mu s$) than the same latency observed
after the first PP-IRQ issued by $E_M$. This can be explained as
follow.  When station $E_M$ triggers the activation PP-IRQ, station $E_T$ is just
returning from the interrupt context of the interrupt PP-IRQ previously triggered by
$E_M$. As a consequence, the $E_M$ interrupt latency is significantly reduced.  It
is worth recalling that station $E_T$ executes the Xenomai platform with minimal
load, thus between the return of the first and the second interrupt triggered by
$E_M$, no other interrupt can happen. However, the standard deviation is significantly
increased, as the response time of the interrupt device (APIC) is source of temporal
variation.

Except for this increase of the latencies by the $\delta$ interrupt latency at
station $E_T$, and its related standard deviation, results obtained with the second
experimental configuration are similar to those obtained with the first experimental
configuration.


\section{Related work}
\label{sec:trabRel}

% Alguns resultados experimentais comparando Linux$^{\mathbf{Prt}}$ com
% Linux$^{\mathbf{Std}}$ são apresentados por \cite{Rostedt07}. Duas métricas são
% usadas, latências de interrupção e de escalonamento, relacionadas ao escalonamento
% de uma tarefa periódica.  No entanto, os experimentos foram realizados sem
% sobrecarga do processador e a metodologia usada não foi precisamente
% descrita. \cite{Siro07} realizam um estudo comparativo do Linux$^{\mathbf{Prt}}$, de
% RT-Linux \cite{rtLinux} e de Linux$^{\mathbf{RTAI}}$ \cite{RTAI} no qual eles
% utilizam conjuntamente o \ing{benchmark} LMbench \cite{McVoy96} e medidas de desvios
% na execução de uma tarefa periódica. Nestes experimentos, os autores aplicaram uma
% sobrecarga ``média'' do processador, sem considerar carga de interrupção. Num outro
% trabalho, divulgado apenas na Internet \cite{Benoit05}, os desenvolvedores do
% projeto Adeos apresentam resultados comparativos relativos ao Linux com os
% \ing{patches} \preemptt e Adeos. Esta avaliação, bastante abrangente, utiliza o
% \ing{benchmark} LMbench \cite{McVoy96} para caracterizar o desempenho das duas
% plataformas e apresenta resultados de medidas de latências de interrupção realizadas
% com a porta paralela.

Some experimental results comparing Linux$^{\mathbf{Prt}}$ with
Linux$^{\mathbf{Std}}$ are presented in \cite{Rostedt07}. Two metrics are used,
interrupt and scheduling latencies, related to the schedule of a periodic
task. However, the experiments were conducted without loading the processor and the
methodology used was not precisely described. \cite{Siro07} realizes a comparative
study of Linux$^{\mathbf{Prt}}$, RT-Linux \cite{rtLinux} and Linux$^{\mathbf{RTAI}}$
\cite{RTAI} in which they use both LMbench benchmark \cite{McVoy96} and measures of
deviations in the scheduling of a periodic task. In these experiments, the authors
applied an ``average'' load''of the processor, without considering interrupt
load. In another work, only published on the Internet \cite{Benoit05}, the developers of
the project Adeos present comparative results for Linux with the patches
\preemptt and Adeos. This assessment, rather comprehensive, uses LMbench 
benchmark LMbench \cite{McVoy96} to characterize the performance of the two platforms and
presents results of measures taken to interrupt latencies with the parallel port.

% O presente trabalho apresenta resultados de latência de interrupção que confirma os
% resultados obtidos em \cite{Benoit05} para a plataforma Linux$^{\mathbf{Xen}}$. Já
% os resultados encontrados aqui para Linux$^{\mathbf{Prt}}$, sem a opção
% \cod{IRQF\_NODELAY}, diferiram dos apresentados por \cite{Benoit05}, pois uma
% degradação das garantias temporais por esta plataforma foi observada, tal como visto
% na Seção \ref{sec:latIrq}. Em relação às latências de ativação, não temos
% conhecimento de nenhum outro trabalho comparativo. Experimentos idênticos aos
% relatados aqui foram conduzidos para a plataforma Linux$^{\mathbf{RTAI}}$
% \cite{Regnier08b} e os resultados encontrados são semelhantes aos apresentados para
% Linux$^{\mathbf{Xen}}$, dado que ambas plataformas utilizam o mesmo \nanokernel.

This paper presents results of latency of interruption that confirms the results
obtained in \cite{Benoit05} for the Linux platform
Linux$^{\mathbf{Xen}}$. Nevertheless, the results found here for
Linux$^{\mathbf{Prt}}$, without the option \cod{IRQF\_NODELAY}, differed from those
submitted by \cite{Benoit05}, as a degradation of time guarantees by the platform
was observed, as seen in Section \ref{sec:latIrq}. As for activation latencies, we
are not aware of any other comparative work. Experiments similar to those reported
here were conducted for the Linux$^{\mathbf{RTAI}}$ platform \cite{Regnier08b} and
the results are similar to those presented for Linux$^{\mathbf{Xen}}$, since both
platforms use the same Adeos \nanokernel.

\section{Conclusion}
\label{sec:conc}

% Neste trabalho, a avaliação de duas soluções de SOTR baseadas em Linux foi
% realizada. A metodologia experimental permitiu medir as latências de interrupção e
% de ativação, em situações de carga variável, tanto do processador quanto de eventos
% externos tratados por interrupção.  Enquanto o Linux padrão apresentou latências no
% pior caso acima de $100 \mu s$, as plataformas Linux$^{\mathbf{Prt}}$ e
% Linux$^{\mathbf{Xen}}$ conseguiram prover garantias temporais com uma precisão
% abaixo de $20 \mu s$. No entanto, para se conseguir este comportamento em relação ao
% Linux$^{\mathbf{Prt}}$, foi necessário desabilitar \ing{threads} de interrupção,
% tornando o sistema menos flexível. Com tais \ing{threads}, o comportamento de
% Linux$^{\mathbf{Prt}}$ sofre considerável degradação da sua previsibilidade
% temporal.  A plataforma Linux$^{\mathbf{Xen}}$ se mostrou mais adequada, pois tanto
% oferece um ambiente de programação em modo usuário, quanto consegue previsibilidade
% temporal característica de sistema de tempo real.

In this work, the evaluation of two RTOS solutions based on Linux was held. The
methodology has allowed experimental measurements of interrupt and activation
latencies, in situations of variable load, both of the processor and of external
events processed by interruption.  Two experimental configurations were used, the
first based on local measurements was compared with a more regular configuration
based on external measurements through the parallel port.  As both configuration
gives similar results, it appears that the first methodology is founded and can be
efficiently used for the purpose of real-time platforms comparisons.

While the standard Linux presented latencies in the worst case over $100 \mu s$, the
platforms Linux$^{\mathbf{Prt}}$ and Linux$^{\mathbf{Xen}}$ managed to provide
temporal guarantees with a precision below $20 \mu s$. However, in ordrer to achieve
this behaviour with Linux$^{\mathbf{Prt}}$, it was necessary to disable the
interruption threading for the parallel port IRQ line, making the system less
flexible. With such thread, the behavior of Linux$^{\mathbf{Prt}}$ suffers
considerable deterioration of its temporal predictability. The Linux platform
Linux$^{\mathbf{Xen}}$ was found more appropriate since offers a user-mode
programming environment as well as temporal predictability characteristic of
real-time system.

% \small
\bibliographystyle{abbrv}
\bibliography{bib}

\end{document}
