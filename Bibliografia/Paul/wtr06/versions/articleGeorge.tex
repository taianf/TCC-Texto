\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{color}
\usepackage{epsfig}

\usepackage[latin1]{inputenc}
%\usepackage{amsmath}
\usepackage{amssymb, bm}
\usepackage{verbatim}

%\usepackage{savesym}
%\usepackage{tlatex}
%\savesymbol{implies}
\usepackage{amsmath}
%\restoresymbol{TXF}{implies}

\newcommand{\defeq}{\triangleq}

\newcommand{\doris}{\emph{DoRiS}}
\newcommand{\TRT}{\mathcal{T}}
\newcommand{\PSO}{\mathcal{P}}
\newcommand{\WRT}{\mathcal{W}_{h}}
\newcommand{\WEL}{\mathcal{W}_{e}}
\newcommand{\WRE}{\mathcal{W}_{r}}
\newcommand{\WSO}{\mathcal{W}_{s}}
\newcommand{\DRT}{\Delta_{h}}
\newcommand{\DEL}{\Delta_{e}}
\newcommand{\DRE}{\Delta_{r}}
\newcommand{\DSO}{\Delta_{s}}

%\sloppy

\title{Deterministic Integration of Hard and Soft Real-Time Communication
       over Shared-Ethernet}

\author{}
%{Paul D. E. Regnier\inst{1}, George M. Lima\inst{1} }

\address{}
%{Laboratório de Sistemas Distribuídos -- Universidade Federal da Bahia
%  (UFBA)\\
%  CEP 40.170-110 -- Salvador -- BA -- Brazil
%  \email{\{gmlima, pderegnier\}@ufba.br}
%}

\begin{document}

\maketitle

\begin{abstract}
    This paper presents a protocol that makes Ethernet suitable for
    supporting modern real-time systems. Applications that can benefit
    from the proposed protocol are mainly those composed by heterogeneous distributed
    components, which are specified in terms of both hard and soft
    timing constraints. Indeed, using the proposed protocol, hard and soft
    real-time tasks can efficiently and predictably share an Ethernet bus.
    The bus utilization is optimized by an appropriate allocation of the
    available bandwidth into hard and soft communication. Moreover,
    the protocol, compatible with standard Ethernet hardware,
    implements a decentralized medium access control
    that provides a great deal of communication flexibility and reliability.
\end{abstract}

\section{Introduction}

Research on real-time systems have been facing several challenges
in the last few decades. From the application domain perspective,
such systems, once seen as composed by simple, strict and short
hard periodic tasks \cite{Liu73}, typically used for control
loops, nowadays include applications such as telecommunication,
industry, military, aerospace, assets monitoring, automobile etc.
While parts of these systems may contain the usual hard periodic
tasks, requiring known bounded response time and controlled
jitter, other parts may be made of much more complex soft (or
non-hard) tasks to deal sporadic or aperiodic events as is the
case of multimedia tasks \cite{Liu00}, leading to a considerable
task diversity. Further, from the point of view of their structure,
real-time systems has been moving from centralized to distributed.
This requires a suitable communication network capable of dealing
with the new demands task diversity require. Indeed, network
protocols must deal with different traffic patterns in such a way
that they must be able to provide not only controlled jitter and
bounded message transmission time, as required by the usual hard
tasks, but also high throughput, as demanded by soft and other
non-periodic tasks. As a result, industrial communication
networks, known by being reliable and predictable may not suffice
anymore due to their usual low bandwidth.

Ethernet has been considered to be a promising alternative for
designing distributed real-time systems. It provides high
bandwidth, it is cheap, efficient and widely used. However, one
cannot consider its direct use in the real-time systems domain.
This is due to its {\em probabilistic} bus arbitration scheme,
which relies on the Binary Exponential Backoff (BEB) algorithm
used by the Carrier Sense Multiple Access with Collision Detection
protocol (CSMA/CD). In short, messages sent by distinct nodes may
collide if they are sent simultaneously. According to the BEB
algorithm, after detecting the collision, the nodes wait a random
time to retransmit their messages. Further collisions may occur,
messages may get lost or may be non-deterministically
delayed~\cite{CSMA/CD01, Wang99, Dolejs04}. Several solutions to
this problem have been proposed \cite{Wang02,Decotignie05}. This
paper follows the software-based approach, which is based on
building an extra layer on top of the Ethernet layer to provide
deterministic communication guarantees without jeopardizing
flexibility neither increasing hardware costs. More specifically,
our solution is based on sharing the Ethernet with the system
nodes, which can efficiently provide broadcast and multicast
communication, facilities required by many real-time systems.
\footnote{There are many other solutions, either based on hardware
or software modification. Interested readers can refer to
\cite{Hanssen05,Decotignie05}.} A brief description on
related work is given in section \ref{sec:relatedWork}.

This paper describes a broadcast-oriented software-based
shared-Ethernet protocol that has the following main
characteristics: (a) is capable of dealing with different
communication patterns (eg periodic and aperiodic) and
provide temporal isolation by preventing one from interfering in
the other; (b) is reliable and predictable; (c) is efficient; and
(d) can optimize the bus utilization. The proposed
protocol is presented in more details in section
\ref{sec:doris}.

\section{Software-based Shared-Ethernet Approaches to Real-Time Ethernet
         \label{sec:relatedWork}}

Perhaps the simplest deterministic software-based solution is to
divide time into a sequence of slots, each of which is assigned to
a specific system node. Nodes can transmit their message only in
their respective time slot. This scheme, known as Time Division
Multiple Access (TDMA) \cite{Kurose05}, gives a great deal of
communication predictability. This characteristic suits well
industrial applications, composed mainly by hard periodic tasks.
However, when different traffic patterns are considered, TDMA is
too inflexible and inefficient to be recommended. For example, a
node requiring to transmit multimedia related messages may have to
wait for its slot too long even if the bus is not being used.

Token-based protocols are usually more flexible than TDMA. They
use a token to give permission to a node to transmit messages. The
nodes are organized in some kind of logical ring and the token
rotates on the ring. Only the token holder node has the right to
transmit on the bus. The token can be explicit or implicit.
Explicit token is used by protocols like RETHER
\cite{Venkatrami94} or RTnet \cite{Hanssen05}. Although these
protocols deal with different traffic patterns, they introduce
extra overhead in case of token loss.

Implicit token protocols based on Timed Packet Release mechanism
(TPR) offer a better alternative \cite{Pritty95, Carreiro03}. In
brief, a token is implicitly passed on to the next node
independently of whether or not the previous node in the ring
transmits its message. In other words, the absence of message
means that a node is giving up its right to use the bus. Thus, the
bus can be utilized more efficiently. However, the speed of
rotating the token must be carefully calculated to fit to the
slowest node on the ring since each node has to observe any bus
activity. Therefore, this approach may suffer from performance
degradation in systems composed of heterogeneous nodes with
different traffic demands.

Other protocols, like FTT \cite{Pedreiras02}, use a master-slave
model to control bus access. Here a special node plays the hole of
an arbiter (the master), polling other nodes (the slaves). Slaves
are allowed to transmit their messages only if they get permission
to do so. This model can handle hard and soft traffics
but exhibits single-point of failure, which can be dealt with if
the master is replicated. In any case, there is an asymmetric load
distribution on the net, which may imply problems of scalability
and performance.

In this paper we mix two approaches together, TDMA and implicit
token, to get the best out of each one. TDMA is used to create
two windows to predictably deal with hard and soft
messages, respectively. Inspired by the Virtual Token Protocol
(VTPE) \cite{Carreiro03}, the bus access in each window is
controlled by organizing the nodes in two rings, one for each
window, and by using implicit token so that bus utilization can be
optimized. The proposed protocol, called \doris{}, which stands
for {\em Double Ring Service for Real-Time Ethernet}, is flexible
and efficient. Unlike VTPE, slow nodes do not compromise
performance since while they are processing incoming messages,
fast nodes may use the bus for soft traffic.


\section{DoRiS}
\label{sec:doris}

\doris{} is a collision-free protocol built on top of Ethernet
hardware. Located between the IP and the physical layers of the
Ethernet stack, the protocol works as a logical layer, extending
the CSMA/CD MAC layer.

\doris{} was designed to support hybrid systems where industrials
sensors, actuators and controllers share the communication network
with multimedia and others soft applications. It is
important to notice that the processing speed and the
communication characteristics of these two types of application
differ to a great extent. Indeed, most industrials
appliances available on the shelf have low processing capacity
compared to Ethernet bandwidth. For example, Carreiro et al. [2003]
assumes that industrial appliances spend up to
$111 \, \mu s$ to process an incoming message of 64B. As the
transmission time on a 100Mbps Ethernet link of such
message is $5.12\,\mu s$, this allows only about $4.6\%$ of bus
utilization for hard real time communication.
On the other hand, multimedia application requires much higher transmission
rates and faster processing nodes. Taking these observations into
consideration, \doris{} provides both temporal guarantees for hard
real-time tasks and high bandwidth access to soft and best effort
ones.

In order to achieve the integration of distinct traffic patterns,
a scheme based on TDMA and virtual token is used. After presenting
the computation model, this scheme will be presented in more
details in the next few sections. We will focus the protocol
description on the functions that guarantee the shared medium
access without collision. As the functions to receive messages
are based on the Ethernet standard functions, they will not be
described. Also, for the sake of space, mechanisms for
implementing node synchronization, group membership and fault
tolerance will not be considered.

\subsection{Computation Model
            \label{sec:model}}

We consider a set of nodes connected to each other through a
shared-Ethernet segment, the \doris{} segment. Each node may run
hard real-time or soft tasks, each of which is uniquely
identified in the system. For the sake of notation, we refer to
the former simply as {\em tasks} while to the latter as {\em
processes} and denote them as the ordered sets
$\TRT=\{T_1,T_2,\ldots,T_{N_{\TRT}}\}$ and $\PSO
=\{P_1,P_2,\ldots,P_{N_{\PSO}}\}$, respectively. These sets
represent the two logical rings of DoRiS.

Received messages are processed by the tasks within a maximum
processing time, denoted by $\pi$. This time is usually associated
to message processing by industrial appliances (micro-controllers,
sensors etc). We assume that these appliances, called hereafter
{\em slow nodes}, need temporal guarantees and that their messages
are short, usually periodic, and have hard real-time constraints.
Such messages, called \emph{slot messages}, are assumed to have a
constant length of 64B and are transmitted through the network
within a maximum transmission time $\delta \ll \pi$. We also
consider that the task processing time regarding message
transmission is incorporated into the the task computation time
and so can be neglected during the protocol description.

We assume the publish-subscribe communication
model~\cite{Dolejs04} according to which whenever a node has a
slot message to send, it transmits such a message using the
Ethernet broadcast standard address (48 address bits set to 1).
Each task receives and processes every hard real-time message.
Based on the source address, tasks then decide wether they are
interested in the message. In practical applications, tasks may
not have to process all messages or may drop unused messages.
However, for the sake of model simplification we assume here that
all messages are fully processed.

As mentioned before, if only slow nodes are present in the
\doris{} segment, the bus may be under-utilized. Thus, if there
are fast nodes connected to the bus, \doris{} allows them to use
this spare bandwidth. Assuming that nodes are equipped with
receiving buffers, receiving and processing of slot messages are
independent actions that can happen simultaneously. Therefore, the
maximum bandwidth used for real-time traffic is $B_m = \delta /
\pi$. It is important to notice that $B_m$ indicates the bound
above witch buffer overflows occur since the slowest node will
receive more slot messages than it can process. Also, note that
since there are buffers at the nodes, more than one message can be
sent in a row.

\subsection{The Protocol Structure}

The communication on a \doris{} segment is structured in (sliding)
cycles, each of which is made of $N_{\TRT}$ {\em elementary
sequences} (ES). A new cycle starts at the beginning of each ES.
Each ES is itself divided into two windows, $\WRT$ and $\WSO$,
respectively associated to hard real-time and soft traffic.
Tasks send messages only in $\WRT$ while processes use $\WSO$ to
transmit theirs. The size of these two windows are respectively
denoted $\DRT$ and $\DSO$. Thus, the elementary sequence size is
defined by $\Delta_{es} = \DRT + \DSO$. Figure
\ref{fig:dorisStruct} illustrates a \doris{} cycle with a focus on
the $i^{th}$ ES.

\begin{figure}[ht]
  \index{fig!dorisStruct}
   \centering
  \input{fig/dorisStruct.pstex_t}
  \caption{The $\mathrm{N_T}$ elementary sequences of a \doris{} cycle
  \label{fig:dorisStruct}}
\end{figure}

We assume that nodes are equipped with a local timer. For
simplicity, if $T_i$ (or $P_i$) and $T_j$ (or $P_j$) are two tasks
(processes) located in the same node, their local timers $t_i$
and $t_j$, instances of the node timer, are equal.
These timers are used to divide the bandwidth into elementary
sequences. For that purpose, they assume values from $0$ to
$\Delta_{es}$ and are reset periodically at the end of each ES.
Each task $T_i$ or process $P_i$ maintains also a local
integer counter, denoted $K^T_{i}$ or $K^P_{j}$, respectively.
Local timers and counters are used to organize the token circulation
between both rings $\TRT$ and $\PSO$ as will be seen in the following
two sections.

To allow some flexibility and scheduling policy, the hard
real-time window is further divided into two sub-windows, the
elementary ($\WEL$) and the reservation ($\WRE$) windows, as
illustrated in Figure \ref{fig:dorisStruct} for the
$i^{\mathrm{th}}$ ES. Messages sent in these two windows are
called elementary and reservation messages, respectively. $\WRE$
is used to offer a reservation mechanism, which will be explained
in section \ref{sec:reservation}. Both elementary and reservation
messages are slot messages.

\subsection{The Hard Real-Time Ring}

\subsubsection{The Elementary Window}

Tasks are logically organized in a ring where an implicit token
rotates. Only the task that holds the token can have access to the
medium. To organize the virtual token passing, \doris{} combines both
logical and temporal conditions.

A task $T_i$ is said to hold the token in $\WEL$ if its counter
$K^T_i$ equals $i$ and if its timer \emph{is equal to zero}, that
is when a new elementary window just begins. As there is some local
drift of the timers, we express this condition as an inequality,
where $t_i$ has to be less than the inter-frame gap time
(IFG)~\footnote{IFG is a parameter of the Ethernet standard
\cite{CSMA/CD01}, which is defined to be equal to the time a
signal takes to propagate on the longest shared-Ethernet segment
allowed by the standard.}. The following predicate formalizes
these conditions:

\begin{tabular}{ l l }
  $ElemHolder(i) \defeq$ & $(0 \leqslant t_{i} < IFG) \;
                             \wedge \; (K^T_{i} = i)$
\end{tabular}

Whenever $ElemHolder(i)$ becomes true, $T_i$ broadcasts an
elementary message by executing the $sendElemMsg(i)$ operation,
which consists of transmitting its local counter $K^T_i$, its
reservation list (see next section), and its optional data if
there are any. Sending an elementary message in each ES makes it
easier to implement failure detectors and gives communication
regularity, characteristics required by hard real-time tasks.

At the beginning of each cycle the counter $K_i^T$ is set to 1 and
is (periodically) incremented by 1 at the end of every ES. As
there are exactly $N_T$ elementary sequences in a cycle, every
task in $\TRT$ will periodically receive the token in $\WEL$ once
per cycle.

Observe that, as every ES contains one elementary message, tasks
can synchronize themselves by using the End-Of-Frame interrupt of
the broadcast message. Also, if an elementary message suffers an
omission fault, the progression of the local counters will not be
blocked, as they rely on local timers. As a consequence, the
maximum drift of local timers is bounded according to the
synchronization protocol and the number of consecutive omissions
assumed to be tolerated \cite{PCSP02}.

\subsubsection{The Reservation Window}
\label{sec:reservation}

The reservation scheme is used to implement some message priority
policy by means of the reservation windows, which make
some extra bandwidth available for the tasks.
To implement this scheme each task $T_i$ sends its
reservation list upon the
execution of $sendElemMsg(i)$,
as we briefly saw in the previous section.
For each task $T_i$ this list is a possibly empty subset of
$\{1, 2, \dotsc, N_{T}\} - \{i\}$ that indicates the elementary
sequences of the next cycle in which $T_i$ will use $\WRE$ to
transmit extra data. For example, reservation list $\{2,4\}$ sent
by $T_3$ means that $T_3$ requests $\WRE^2$ and $\WRE^4$ in the
current cycle. If $T_i$ sends an empty list, no reservation is requested.

As can be noted, the reservation list size is up to $N_T-1$ and can
be implemented as a bit vector. An efficient alternative
for of (implicitly) implementing this list
is to send the number of windows requested.
In this case, a request carrying $k>0$ could mean that the next $k$ free windows
were to be reserved. This would imply that $\lceil \log_2 (N_T-1) \rceil$ message
bits must be used to represent the list instead of $N_T-1$ bits.
Nevertheless, one can find out
a trade-off between the list size and the maximum number of $\WRE$ per
task that could be reserved. We consider here the list size as an
implementation detail and do not impose any restriction to it.

When a task receives a reservation list, it updates a boolean vector of
size $N_{\mathcal{T}}$, denoted $\Gamma_i$.
If the entry $\Gamma_i[j]$ is true, the $\WRE^j$ is reserved.
Otherwise, such a window is free.
The value true for $\Gamma_i[j]$ is valid only for a cycle.
Thus, $\Gamma_i[j]$ is reset after $N_T$ ES have been finished since the time
$\Gamma_i[j]$ was set.

It is important to note that
{\em at least one reservation window per cycle is guaranteed to the tasks}.
Indeed, considering task $T_i$, it is the first one to
have the right to request the reservation of $\WRE^{i+N_T}$. Thus,
no other task $T_j$ ($j < i$) can have reserved $\WRE^{i+N_T}$ before.

It is clear that for a task to transmit its message in a reservation window, it
has to be sure that the reservation procedure was successful and such
a reservation window is not reserved by any other task.
For example, omission faults of elementary message could make
$\Gamma_i$ inconsistent.
The protocol deals with this requirements in a very efficient way
by establishing a reservation condition.
Indeed, $T_i$ may only request a reservation if its
{\em state is consistent}, which
is formalized by the following predicate:

\begin{tabular}{ l p{14cm} }
  $Consistency(\Gamma_i) \defeq$ & $T_i$ has received all elementary \newline
                                 messages sent in the previous cycle\\
\end{tabular}

Let $\DEL=\delta + IFG$ be the size of $\WEL$. A task $T_i$
is said to hold the token in $\WRE^j$ if it has a reservation for
$\WRE^j$ and if its timer $t_i$ is in the interval
$[\DEL , \DEL + IFG)$. More formally,

\begin{tabular}{ l p{14cm} }
  $ReserHolder(i) \defeq$ & $(\DEL \leqslant t_i < \DEL + IFG)
                  \; \wedge \; (\Gamma_i[K_i^T] = i)$\\
\end{tabular}

It is important to emphasize that the reservation scheme offers
interesting properties. First, $\Gamma_i$ can be efficiently implemented.
Indeed, it is a bit vector and
there is no need of clocks to reset the vale of $\Gamma_i$  since
the elementary sequence periodicity can be used as a logical clock.
Second, as we have seen,
reservations are always safely carried out even when faults
are considered. Third, there are three implicity priority levels:
one that uses elementary windows only;
the other is regarding the guaranteed reservation window;
and the third that makes use of the free (but not guaranteed)
reservation windows.

\subsection{The Soft Ring $\PSO$}

As in the hard ring, processes
use their timers to control the soft ring, using
elementary messages as temporal
references. In brief, the end of every $\WRT$ works as a pulse,
marking the beginning of the soft windows.
Like the VTPE protocol \cite{Carreiro03},
this is actually a decentralized version of
the Timed Packet Release mechanism~\cite{Pritty95}
since no node/process plays a central role
for sending the pulse.

Unlike the hard ring,
processes do not have to send messages always.
The token rotates based on the carrier sense
mechanism provided by Ethernet.
At the beginning of each $\WSO$, every process senses the medium.
If it remains idle for a time greater than $d > 0$, a parameter
of the protocol, it increments its local counter $K_i^P$.
Otherwise, some process is transmitting and the medium is busy.
In this case, all process wait for the
End-Of-Frame interrupt associated to the current transmission and then
increments their counter.
The parameter $d$ is chosen to be $1 \,
\mu s$ (considering a 100 MB bus).
This ensures unambiguous detection of the start of a packet
transmitted by a previous node \cite{Pritty95}.

We say that a process $P_i$ is allowed to transmit when the following
enabling predicate holds:

\begin{tabular}{ l p{14cm} }
  $SoftHolder(i) \defeq$ & $\DRT \leqslant t_i < \DRT + \DSO \; \wedge \;$
                  Medium is iddle $\; \wedge \;K_{i}^P = i$\\
\end{tabular}

%This value, is just greater than the IFG of 96 bits time
%($0.96 \, \mu s$).
While the token rotates, the remaining time
in $\WSO$ decreases. Thus, a process $P_i$ could receive the token
without enough time to transmit its message in the current $\WSO$.
As this could happen an arbitrary number of times, a process might
suffer starvation.
To solve this problem, we define a ``STOP'' message as a special
slot message that stops the token time passing in the current window.
Note a STOP message is to distinguish the case
that a process has nothing to send from the case it has not enough time
to transmit. The process that sends a STOP message will be the first
to hold the token in the next $\WSO$.

In order to the STOP message mechanism to be effective,
there has to be enough time (ie $\delta$) for a process to send
a slot message whenever it receives the token. This minimum time is
guaranteed by the fact that $\WSO$ ends when the remaining time
is equal to $\delta$.

Its important to consider fault scenarios. Indeed,
a process $P_i$ may suffer a transient or processing
timing fault. In this, its local counter
$K_i^P$ may be out of date. There are two cases that have to be
dealt with. First, if $P_i$ observes an empty $\WSO$, the process with
the smaller identifier is assumed to first hold
the token in the next $\WSO$. This is done by
resetting $K_i^T$ to 1 at all processes. Second,
if $P_i$ observes a soft message transmission, it
identifies the message sender from the source address.
Using the ES beginning instant and the message Start-Of-Frame
instant, $P_i$ localizes the token.
As can be seen, the protocol is safe in both cases.


\subsection{Conclusion}
\label{sec:conclusion}

As two slot messages may be sent in each
ES, every slow nodes needs $2 \pi$ to process them.
%($\pi$ is the processing time of a slot message by the slowest node).
The existence of buffers at the nodes allows a task to process a
message while receiving another, thus, $\DSO$ has to be greater
than $2 \pi - \DRT$.

We choose the minimum value $\DSO = 2 \pi - \DRT$ in order to
maximize the bandwidth available for $\TRT$. Thus, the bandwidth
$B_{h}$ available for the real time ring is: $B_{h} = 2 \delta /
\Delta_{es}$ As $\Delta_{es} = \DRT + \DSO$, we can deduce that
$B_{h} = \delta / \pi = 4,6\%$


In order to allow any size of message inside the range of the
Ethernet standard (fom 64 to 1518 bytes), which corresponds to a
temporal range from $\delta = 5.12$ to $\delta_m = 121.44 \, \mu
s$, we assume that $2 \pi$ is greater than $\delta_m$.
Practically, we assume that $\pi = 111 \; \mu s$ as in \cite{Carreiro03}.

The remaining bandwidth (95,4\%) is used by the soft ring. In the
worst case, if only one process wants to tranmit, it can suffer the 
maximum delay of $N_T \, d$. Thus, if all processes wants to transmit,
the last to receive the token may waits the worst token rotation time
of $N_T \, d + (N_T - 1) \DSO$.

\begin{comment}

In a scenario where a $\WSO$ contains one message of size $\delta_m$,
the remaining time available for the timed token circulation
mechanism is $\DSO -\delta_m - 3 d (97 \; \mu s)$, as the STOP
mechanism consumes $3 d$.
Thus the number of soft nodes that the token may visit
during this $\WSO$ is aproximatively 85.

Observe that if no reservation are made in a specific elementary
sequence, the corresponding slot remains empty, i.e. the medium
remains iddle. This causes a certain waste of the bandwidth (about
2.3\% cf. section \ref{sec:performance}) which could be improved for
the soft communication. Nevertheless, to avoid that waste,
the soft processes should observe the hard real time
communication and maintain a consistent $\Gamma$ tuple. This would
generates new faults scenariis in case of message loss. To let the
protocol simpler and safer, we choose a deterministic and periodic
mecanism that provides efficient fault detection and isolation of
both kind of communication.

Let the token rotation time THT be the time between two elementary
message send by a given process. THT is constant and is equal to the
duration of a cycle: $N_T \Delta_{es}$.

Thus the total bandwidth available for a given task is $B_h / N_T$.

In the ASYNC case and if $\pi$ is much smaller than $\delta_m$, it
is possible to increase the value of $\alpha$ to optimize the
division of the bandwidth between the two rings.
\end{comment}

\section{Conclusion}
\label{sec:conclusion}

\doris{}, a protocol that allows the co-existence of both hard and soft real-time traffics
on the same Ethernet segment was described. \doris{} offers periodicity
for hard real-time messages and high transmission rates to soft ones. Both types of
real-time traffic are temporally isolated from each other and the bus utilization
can be optimized.

The described protocol is currently been formally specified and then will be
implemented, possibly using some open source real-time operating system.
Further protocol functionalities must be considered in future work.
For example, appropriate priority polices can be used to
take advantage of the reservation mechanism. Also, mechanism such as
membership control and dynamic reconfiguration can play an important role
in increasing the reliability and flexibility of \doris{}.

\bibliographystyle{sbc}
\bibliography{bib}

\end{document}
