\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{color}
\usepackage{epsfig}

\usepackage[latin1]{inputenc}
%\usepackage{amsmath}
\usepackage{amssymb, bm}
\usepackage{verbatim}

%\usepackage{savesym}
%\usepackage{tlatex}
%\savesymbol{implies}
\usepackage{amsmath}
%\restoresymbol{TXF}{implies}

\newcommand{\defeq}{\triangleq}

\newcommand{\doris}{\emph{DoRiS}}
\newcommand{\TRT}{\mathcal{T}}
\newcommand{\PSO}{\mathcal{P}}
\newcommand{\WRT}{\mathcal{W}_{h}}
\newcommand{\WEL}{\mathcal{W}_{e}}
\newcommand{\WRE}{\mathcal{W}_{r}}
\newcommand{\WSO}{\mathcal{W}_{s}}
\newcommand{\DES}{\Delta_{es}}
\newcommand{\DRT}{\Delta_{h}}
\newcommand{\DSO}{\Delta_{s}}
\newcommand{\DEL}{\Delta_{e}}
\newcommand{\DRE}{\Delta_{r}}

%\sloppy

\title{Deterministic Integration of Hard and Soft Real-Time Communication
       over Shared-Ethernet}

\author{}
%{Paul D. E. Regnier\inst{1}, George M. Lima\inst{1} }

\address{}
%{Laboratório de Sistemas Distribuídos -- Universidade Federal da Bahia
%  (UFBA)\\
%  CEP 40.170-110 -- Salvador -- BA -- Brazil
%  \email{\{gmlima, pderegnier\}@ufba.br}
%}

\begin{document}

\maketitle

\begin{abstract}
    This paper presents a protocol that makes Ethernet suitable
    for supporting modern real-time systems. Applications that
    can benefit from the proposed protocol are mainly those
    composed of heterogeneous distributed components, which are
    specified in terms of both hard and soft timing constraints.
    Indeed, using the proposed protocol, hard and soft real-time
    tasks can efficiently and predictably share an Ethernet bus.
    The bus utilization is optimized by an appropriate allocation
    of the available bandwidth into hard and soft communication.
    Moreover, the protocol, compatible with standard Ethernet
    hardware, implements a decentralized medium access control
    that provides a great deal of communication flexibility
    and reliability.
\end{abstract}

\section{Introduction}

Research on real-time systems have been facing several challenges
in the last few decades. From the application domain perspective,
such systems, once seen as composed of simple, strict and short
hard periodic tasks, typically used for control
loops, nowadays include applications such as telecommunication,
industry, military, aerospace, assets monitoring, automobile etc.
While parts of these systems may contain the usual hard periodic
tasks, requiring known bounded response time and controlled
jitter, other parts may be made of much more complex soft (or
non-hard) tasks to deal with sporadic or aperiodic events \cite{Liu00}, 
leading to a considerable
task diversity. Further, from the point of view of their structure,
real-time systems have been moving from centralized to distributed.
This requires a suitable communication network capable of dealing
with the new demands task that diversity requires. Indeed, network
protocols must deal with different traffic patterns and
must provide not only controlled jitter and
bounded message transmission time, as required by the usual hard
tasks, but also high throughput, as demanded by soft and other
non-periodic tasks. As a result, industrial communication
networks, known by being reliable and predictable, may not suffice
anymore due to their usual low bandwidth.

Ethernet has been considered a promising alternative for
designing distributed real-time systems. It provides high
bandwidth, it is cheap, efficient and widely used. However, one
cannot consider its direct use in the real-time systems domain.
This is due to its {\em probabilistic} bus arbitration scheme,
used by the Carrier Sense Multiple Access with Collision Detection
protocol (CSMA/CD)
~\cite{CSMA/CD01, Dolejs04}. Several solutions to this %problem
lack of determinism, either based on hardware or software
modification, have been proposed along the last three decades. A
brief description on related work is given in section
\ref{sec:relatedWork}, although interested readers can refer to
\cite{Hanssen03, Decotignie05} for more details. To the best of
our knowledge, none of them succeed to offer hard real-time
guarantees, high throughput and fault tolerance mechanism using a
decentralized medium access control approach without hardware
modification.

This paper describes a
broadcast-oriented software-based shared-Ethernet protocol, which
consists of an extra layer built on top of the Ethernet layer. The
protocol, presented in section \ref{sec:doris},
provides deterministic communication guarantees without
jeopardizing flexibility neither increasing hardware costs. Also,
it preserves the Ethernet broadcast communication capacity,
facility required by many real-time systems. The protocol is
reliable, predictable, efficient, optimizes the bus utilization,
and is capable of dealing with different communication patterns
(eg periodic and aperiodic). By providing an innovative dynamic
reservation mechanism, the protocol also offers an adaptable
bandwidth allocation to hard real-time traffic.

\section{Software-based Ethernet Approaches to Real-Time Ethernet
         \label{sec:relatedWork}}

Perhaps the simplest deterministic software-based solution is to
divide time into a sequence of slots, each of which is assigned to
a specific system node. Nodes can transmit their message only in
their respective time slot. This scheme, known as Time Division
Multiple Access (TDMA) \cite{Kurose05}, gives a great deal of
communication predictability. This characteristic suits well
industrial applications, composed mainly of hard periodic tasks.
However, TDMA lacks flexibility since even if a station
has nothing to transmit, its time slot will be wasted.

Token-based protocols are usually more flexible than TDMA. They
use a token to give permission to a node to transmit messages. The
nodes are organized in a logical ring and the token
rotates on the ring. Only the token holder node has the right to
transmit on the bus. The token can be explicit or implicit.

Explicit token uses a token message to allow nodes to transmit.
Whenever a node terminates a transmission, it sends the token to
the next node according to the schedule. RETHER
\cite{Venkatrami94} and RTnet \cite{Hanssen05} are examples of
explicit-token protocols. Although these
protocols deal with different traffic patterns, they introduce
extra overhead in case of token loss.

Implicit-token protocols based on Timed Packet Release mechanism
(TPR) offer a better alternative \cite{Pritty95, Carreiro03, ControlNet97}.
In brief, a token is implicitly passed on to the next node
independently of whether or not the previous node on the ring
transmits its message. In other words, the absence of message
means that a node is giving up its right to use the bus. Thus, the
bus can be utilized more efficiently.

Other protocols, like FTT \cite{Pedreiras02}, use a master-slave
model to control bus access. Here a special node plays the role of
an arbiter (the master), polling other nodes (the slaves). Slaves
are allowed to transmit their messages only if they get permission
to do so. This model can handle hard and soft traffics
but exhibits single point of failure, which can be dealt with if
the master is replicated. In any case, there is an asymmetric load
distribution on the net, which may imply problems of scalability
and performance.

In this paper we mix two approaches together, TDMA and implicit
token, to get the best out of each one. TDMA is used to create
two windows to predictably deal with hard and soft
messages, respectively. Inspired by the Virtual Token Protocol
(VTPE) \cite{Carreiro03}, the bus access in each window is
controlled by organizing the nodes in two logical rings, one for each
window, and by using implicit token so that bus utilization can be
optimized. The proposed protocol, called \doris{}, which stands
for {\em Double Ring Service for Real-Time Ethernet}, is flexible
and efficient.


\section{DoRiS}
\label{sec:doris}

\doris{} is a collision-free protocol built on top of Ethernet
hardware. Located between the IP and the physical layers of the
Ethernet stack, the protocol works as a logical layer, extending
the CSMA/CD MAC layer.
\doris{} was designed to support hybrid systems where industrials
sensors, actuators and controllers share the communication network
and other soft applications. It is
important to notice that the processing speed and the
communication characteristics of these two types of application
differ to a great extent. Indeed, most industrials
appliances available on the shelf have low processing capacity
compared to Ethernet bandwidth. For example, Carreiro et al. [2003]
assumes that industrial appliances spend up to
$111 \, \mu s$ to process an incoming message of 64B. As the
transmission time on a 100Mbps Ethernet link of such
message is $5.12\,\mu s$, this allows only about $4.6\%$ of bus
utilization for hard real-time communication.
On the other hand, multimedia application requires much higher transmission
rates and faster processing nodes. Taking these observations into
consideration, \doris{} provides both temporal guarantees for hard
real-time tasks and high bandwidth access to soft and best effort
ones.

After presenting
the computation model, the \doris{} scheme will be presented in more
details in the next few sections. We will focus the protocol
description on the functions that guarantee the shared medium
access without collision. As the functions to receive messages
are based on the Ethernet standard functions, they will not be
described. Also, due to the lack of space, mechanisms for
implementing node synchronization, group membership and fault
tolerance will not be considered.

\subsection{Computation Model
            \label{sec:model}}

We consider a set of nodes connected to each other through a
shared-Ethernet segment, the \doris{} segment. Each node may run
hard real-time or soft tasks, each of which is uniquely
identified in the system. For the sake of notation, we refer to
the former simply as {\em tasks} while to the latter as {\em
processes} and denote them as the ordered sets
$\TRT=\{T_1,T_2,\ldots,T_{N_T}\}$ and $\PSO
=\{P_1,P_2,\ldots,P_{N_P}\}$, respectively. These sets represent
the two logical rings of DoRiS, where a single token rotates.

Received messages are processed by the tasks within a maximum
processing time, denoted $\pi$. This time is usually associated to
message processing by industrial appliances (micro-controllers,
sensors etc). We assume that these appliances, called hereafter
{\em slow nodes}, need temporal guarantees and that their messages
are short, usually periodic, and have hard real-time constraints.
Such messages, called \emph{hard messages}, are assumed to have a
constant length of 64B and are transmitted through the network
within a maximum transmission time $\delta \ll \pi$. We also
consider that the task processing time regarding message
transmission is incorporated into the task computation time
and so can be neglected during the protocol description.

Our protocol uses the publish-subscribe communication
model~\cite{Dolejs04} according to which whenever a task or
process has a message to send, it transmits such a message using the
Ethernet broadcast standard address (48 address bits set to 1).
When various applications are located at the same node,
they uniquely identify their messages using the
type field of the Ethernet frame.
Each task/process receives and processes every message.
Based on the source address, they then decide whether they are
interested in the message. In practical applications, tasks may
not have to process all messages or may drop unused messages.
However, for the sake of model simplification we assume here that
all hard real-time messages are fully processed by the tasks.

As mentioned before, if only slow nodes are present in the
\doris{} segment, the bus may be under-utilized. However, if there
are fast nodes connected to the bus, \doris{} allows them to use
this spare bandwidth. Assuming that nodes are equipped with
receiving buffers, receiving and processing hard messages are
independent actions that can happen simultaneously. This also
implies that more than one message can be sent in a row.
Therefore, the maximum bandwidth rate available for real-time
traffic is $B_m = \delta / \pi$. It is important to notice that
$B_m$ indicates the bound above which buffer overflows occur since
the slowest node will receive more hard messages than it
can process.

\subsection{The Protocol Structure}

The communication on a \doris{} segment is structured as an
infinity sequence of time slots, called {\em
elementary sequences} and denoted $ES_k$ for $k \in \mathbb{N}^*$.
Each $ES_k$ is itself divided into two windows,
$\WRT^k$ and $\WSO^k$, respectively associated to hard and
soft real-time traffics. Tasks send messages only in $\WRT$ while
processes use $\WSO$ to transmit theirs. The size of these two
windows are respectively denoted $\DRT$ and $\DSO$. Thus, the
elementary sequence size is defined by $\DES = \DRT + \DSO$.

We define $\Omega_k$ as the ordered list of $N_T$ consecutive
elementary sequence that begins by $ES_k$, ie
$\Omega_k = (ES_k, ES_{k+1}, \dotsc , ES_{k+N_T-1})$.
Figure \ref{fig:dorisStruct} illustrates $\Omega_1$ focusing
on $ES_i$.

\begin{figure}[ht]
  \index{fig!dorisStruct}
   \centering
  \input{fig/dorisStruct.pstex_t}
  \caption{The $\mathrm{N_T}$ ES of $\Omega_1$ with a focus on $ES_i$
  \label{fig:dorisStruct}}
\end{figure}

We assume that nodes are equipped with a local timer. For
simplicity, if $T_i$ (or $P_i$) and $T_j$ (or $P_j$) are two tasks
(processes) located in the same node, their local timers $t_i$
and $t_j$, instances of the node timer, are equal.
These timers are used to divide the bandwidth into elementary
sequences. For that purpose, they assume values from $0$ to
$\DES$ and are reset periodically at the end of each $ES$.

Each task $T_i$ and process $P_i$ maintains also local counters,
respectively denoted $K^T_{i}$ ($1 \leqslant K^T_{i} \leqslant N_T$)
and $K^P_{j}$ ($1 \leqslant K^P_{i} \leqslant N_P$).
Local timers and counters are used to organize the token circulation
between both rings $\TRT$ and $\PSO$ as will be seen in the following
two sections.

To allow for some flexibility and scheduling policy, the hard
real-time window $\WRT^k$ is further divided into two sub-windows, the
elementary ($\WEL^k$) and the reservation ($\WRE^k$) windows, as
shown in Figure \ref{fig:dorisStruct} for $ES_i$.
Messages sent in these two windows are
called elementary and reservation messages, respectively. $\WRE$
is used to offer a reservation mechanism, which will be explained
in section \ref{sec:reservation} Both elementary and reservation
messages are hard messages.

\subsection{The Hard Real-Time Ring}

\subsubsection{The Elementary Window}

Tasks are logically organized as a ring where a unique implicit
token rotates, granting medium access authorization according
to temporal and logical rules.

Consider a window $\WEL^k$. We define the mapping $Id$ from $\mathbb{N}^*$
in $\{1, \ldots , N_T\}$ by $Id(k) = (k-1) \, mod(N_T) + 1$.
Let $i = Id(k)$, $T_i$ is said to hold the token in $\WEL^k$
if its counter $K^T_{i}$ equals $i$ and if its timer is equal to zero
(ie when $\WEL^k$ just begins). We assume
here that the timer drift is bounded by the inter-frame gap
time (IFG) \cite{CSMA/CD01}.
%(this parameter of the Ethernet
%standard \cite{CSMA/CD01} is defined to be equal to the time a
%signal takes to propagate on the longest shared-Ethernet segment
%allowed by the standard).
We will see at the end of this section
how this can be guaranteed by the protocol. Therefore, we express
the equality condition by means of an inequality, where $t_i$ has
to be less than IFG. The following predicate formalizes these
conditions:%%% with $i(k)$ written $i$

\begin{tabular}{ l l }
  $ElemHolder(i) \defeq$ & $(0 \leqslant t_{i} < IFG) \;
                             \wedge \; (K^T_{i} = i)$
\end{tabular}

Whenever $ElemHolder(i)$ becomes true, $T_i$ broadcasts an
elementary message by executing the $sendElemMsg(i)$ operation,
which consists of transmitting its local counter $K^T_i$, its
reservation list (see next section), and its optional data if
there are any. Sending an elementary message in each $ES$ makes it
easier to implement failure detectors and gives communication
regularity, characteristics required by hard real-time tasks.

The protocol ensures the following \emph{invariant}.
In each $ES_k$, for all $T_i$, the counter $K_i^T$ equals $Id(k)$.
This is achieved by means of
(periodically) incrementing the local counters by 1
at the end of each $ES$.

Observe that, as each $ES$ contains one elementary message, tasks
can synchronize themselves by using the End-Of-Frame interrupt of
the broadcast message. Also, if an elementary message suffers an
omission fault, the progression of the local counters will not be
blocked, as they rely on local timers. As a consequence, the
maximum drift of local timers has to be bounded according to the
synchronization protocol and the number of consecutive omissions
assumed to be tolerated \cite{PCSP02}.


\subsubsection{The Reservation Window}
\label{sec:reservation}

The reservation scheme is used to implement some {\em classes} of message
by means of the reservation windows, which make
some extra bandwidth available for the tasks.
To implement this scheme each task $T_i$ sends its
reservation list upon the
execution of $sendElemMsg(i)$,
as we described in the previous section.
This list is a possibly empty subset of
$\{1, 2, \ldots, N_{T}\} - \{i\}$ that indicates the reservation
windows in $\Omega_k$ where $T_i$ will transmit extra data.
For example, reservation list $\{2,4\}$ sent
by $T_i$ in $\WEL^k$ means that $T_i$ requests $\WRE^{k+1}$ and
$\WRE^{k+3}$ in $\Omega_k$. If $T_i$ sends an empty list,
no reservation is requested.

When a task $T_i$ receives a reservation list sent in $\WEL^k$,
it updates a boolean vector of size $N_T$, denoted $\Gamma_i$.
If the entry $\Gamma_i[j=ID(k)]$ is true, the $\WRE^k$ is reserved.
Otherwise, such a window is free. The value true for $\Gamma_i[j]$
is only valid for the respective $\Omega_k$.
$\Gamma_i[j]$ is reset after the end of $ES_{k+N_T-1}$.

It is important to note that
{\em at least one reservation window per $\Omega_k$ ($k = 1,2,\ldots$)
is guaranteed to the tasks}. Let $i =Id(k)$ then 
$T_i$ is the first one to have the right to request the reservation
of $\WRE^{k+N_T-1}$.

For a task to transmit its message in a reservation window,
it has to be sure that the reservation procedure was successful and such
a reservation window is not reserved by any other task.
For example, omission faults of elementary messages could let
$\Gamma_i$ be inconsistent.
The protocol deals with this requirements in an efficient way
by establishing a reservation condition.
Indeed, $T_i$ may only request a reservation in $\WEL^k$ if its
{\em state is consistent}, which is formalized by the following predicate:

\begin{tabular}{ l p{14cm} }
  $Consistency(\Gamma_i,k) \defeq$ & $T_i$ has received all elementary
       messages sent in $\Omega_{k - N_T}$\\
\end{tabular}

Let $\DEL=\delta + IFG$ be the size of $\WEL$. A task $T_i$ holds the token
in $\WRE^{k'}$ if it has a reservation for $\WRE^{k'}$ and its timer $t_i$
is in the interval $[\DEL , \DEL + IFG)$. Formally,


 %with $i = (k-1) \, mod(N_T) + 1$
\begin{tabular}{ l p{14cm} }
  $ReserHolder(i,k') \defeq$ & $(\DEL \leqslant t_i < \DEL + IFG)$
                  \newline $\; \wedge \; (K_i^T =Id(k'))$
                  $\; \wedge \; (\Gamma_i[K_i^T] = true)$\\
\end{tabular}

%\begin{comment}
As can be noted, the reservation list size is up to $N_T-1$ and can
be implemented as a bit vector. An efficient alternative
for (implicitly) implementing this list
is to send the number of windows requested.
In this case, a request carrying $k > 0$ would mean that the next $k$
free windows were to be reserved. This would imply that
$\lceil \log_2 (N_T-1) \rceil$ message bits should be used to
represent the implicit list instead of $N_T-1$ bits.
Nevertheless, one can find out
a trade-off between the list size and the maximum number of $\WRE$ per
task that could be reserved. We consider here the list size as an
implementation detail and do not impose any restriction to it.
%\end{comment}

There are other interesting properties that must be highlighted.
First, as it has be seen, reservations are safely carried out even when faults
are considered. Second, there are three implicit message classes:
one that uses elementary windows only;
the other is regarding the guaranteed reservation window;
and the third that makes use of the free (but not guaranteed)
reservation windows. Third, the token rotation time
is constant and equals $N_t \DES$.

\subsection{The Soft Ring $\PSO$}

As in the hard ring, processes use their timers to control
the soft ring, using elementary messages as temporal references.
In brief, the end of every $\WRT$ works as a pulse, marking
the beginning of the soft windows. Like the VTPE protocol
\cite{Carreiro03}, this is actually a decentralized version of
the Timed Packet Release (TPR) mechanism \cite{Pritty95} since no
node/process plays a central role for sending the pulse.

Unlike the hard ring, processes do not have to send messages always.
The token rotates based on the carrier sense mechanism provided by
Ethernet. We introduce $d$, a parameter of the protocol, to define the
following TPR mechanism. At the beginning
of each $\WSO$, each process senses the medium.
For each period $d$ that it senses the medium idle, it
increments its local counter $K_i^P$.
Otherwise, some process is transmitting and the medium is busy.
In this case, each process waits for the
End-Of-Frame interrupt associated to the current transmission and then
increments its counter.
The parameter $d$ is chosen to be $1 \, \mu s$ (considering a 100Mbps bus).
This ensures unambiguous detection of the start of a packet
transmitted by a previous node \cite{Pritty95}.

Hence, a process $P_i$ is allowed to transmit when the following
 predicate holds:

\begin{tabular}{ l p{14cm} }
  $SoftHolder(i) \defeq$ & ($\DRT \leqslant t_i < \DRT + \DSO) \; \wedge \;$
                  (Medium is iddle) $\; \wedge \;(K_{i}^P = i)$\\
\end{tabular}

%This value, is just greater than the IFG of 96 bits time
%($0.96 \, \mu s$).
While the token rotates, the remaining time
in $\WSO$ decreases. Thus, a process $P_i$ could receive the token
without enough time to transmit its message in the current $\WSO$.
As this could happen an arbitrary number of times, a process might
indefinitely be unable to transmit its message.
To solve this problem, we define a ``STOP'' message as a special
soft message (64B) that stops the token time passing in the current $\WSO$.
Thus, a STOP message is used %%%
to distinguish a process
that has nothing to send from a process that has not enough time
to transmit. Indeed, if $P_i$ sends a STOP message, it will be the
first to hold the token in the next $\WSO$.
As $\WSO$ ends when the remaining time is equal to $\delta$,
a process that receives the token always has enough time in the
current $\WSO$ to send a STOP message.

Considering fault scenarios, a process $P_i$
may suffer a crash or a processing timing fault.
In this case, its local counter
$K_i^P$ may be out of date when $P_i$ becomes correct again. There are two cases that have to be
dealt with. First, if $P_i$ observes an empty $\WSO$, the process with
the smaller identifier is assumed to hold
the token first in the next $\WSO$. This is done by
resetting $K_i^T$ to 1 at all processes. Second,
if $P_i$ observes a soft message transmission, it
identifies the message sender from the source address %%%
and type field of the message.
Using the $ES$ beginning instant and the message Start-Of-Frame
instant, $P_i$ localizes the token.
As can be noted, the protocol is safe in both cases.

In the worst case, if only one process wants to transmit, it can suffer the
maximum delay of $N_T \, d$. If all processes wants to transmit,
the last to receive the token may wait the worst token rotation time
of $(N_T - 1) \DSO$.

As for the bandwidth allocation, it is important to
choose adequate values for the window sizes.
As two hard messages may be sent in each
$ES$, each slow node needs $2 \pi$ to process them. Thus, as
there are buffers, $\DSO \geqslant 2 \pi - \DRT$ must hold.
The bandwidth allocation for hard messages is maximized if
one chooses $\DSO = 2 \pi - \DRT$. This gives
$B_{h} = 2 \delta /
\DES$ of the bandwidth for the hard ring.
As $\DES = \DRT + \DSO$, $B_{h} = \delta / \pi$. Assuming $\pi = 111\mu s$,
as in \cite{Carreiro03}, $B_{h} = 4.6\%$.
The remaining bandwidth (95,4\%) is available for the soft ring.

%The \doris{} temporal properties will not be exposed in details
%in this paper due to the lack of space. Nevertheless, we must
%emphasize some important points of our protocol.



\begin{comment}

In a scenario where a $\WSO$ contains one message of size $\delta_m$,
the remaining time available for the timed token circulation
mechanism is $\DSO -\delta_m - 3 d (97 \; \mu s)$, as the STOP
mechanism consumes $3 d$.
Thus the number of soft nodes that the token may visit
during this $\WSO$ is aproximatively 85.

Observe that if no reservation are made in a specific elementary
sequence, the corresponding slot remains empty, i.e. the medium
remains iddle. This causes a certain waste of the bandwidth (about
2.3\% cf. section \ref{???}) which could be improved for
the soft communication. Nevertheless, to avoid that waste,
the soft processes should observe the hard real-time
communication and maintain a consistent $\Gamma$ tuple. This would
generates new faults scenariis in case of message loss. To let the
protocol simpler and safer, we choose a deterministic and periodic
mecanism that provides efficient fault detection and isolation of
both kind of communication.

Let the token rotation time THT be the time between two elementary
message send by a given process. THT is constant and is equal to the
duration of a cycle: $N_T \DES$.

Thus the total bandwidth available for a given task is $B_h / N_T$.

In the ASYNC case and if $\pi$ is much smaller than $\delta_m$, it
is possible to increase the value of $\alpha$ to optimize the
division of the bandwidth between the two rings.
\end{comment}

\section{Conclusion}
\label{sec:conclusion}

This paper has described \doris{}, a protocol based on two logical rings
that allows the co-existence of both hard and
soft real-time traffics on the same Ethernet segment.
Both types of traffic are isolated from each other in the time domain
and the bus utilization can be optimized.
By using the TDMA approach to implement the hard ring, \doris{}
achieves predictability for hard real-time applications.
The implicit token approach was used to control the soft ring.
This configuration can allow for a better bandwidth
allocation. Using typical parameters for slow nodes, it has been shown that
\doris{} can allocate up to $95\%$ of the bandwidth for soft traffic.

The described protocol is currently been formally specified and then will be
implemented, possibly using some open source real-time operating system.
Further protocol functionalities must be considered in future work.
For example, appropriate priority policies can be used to
take advantage of the reservation mechanism. Also, mechanisms such as
membership control and dynamic reconfiguration can play an important role
in increasing the reliability and flexibility of \doris{}.

\small
\bibliographystyle{sbc}
\bibliography{bib}

\end{document}

In order to allow any size of message inside the range of the
Ethernet standard (from 64 to 1518 bytes), which corresponds to a
temporal range from $\delta = 5.12$ to $\delta_m = 121.44 \, \mu
s$, $2 \pi$ has to be greater than $\delta_m$.
This restriction is satisfied by the values $\pi = 111 \; \mu s$
assumed by \cite{Carreiro03}.
