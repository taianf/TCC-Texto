\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage{color}
\usepackage{epsfig}

\usepackage[latin1]{inputenc}
%\usepackage{amsmath}
\usepackage{amssymb, bm}
\usepackage{verbatim}

%\usepackage{savesym}
%\usepackage{tlatex}
%\savesymbol{implies}
\usepackage{amsmath}
%\restoresymbol{TXF}{implies}

\newcommand{\defeq}{\triangleq}

\newcommand{\doris}{\emph{DoRiS}}
\newcommand{\TRT}{\mathcal{T}}
\newcommand{\PSO}{\mathcal{P}}
\newcommand{\WRT}{\mathcal{W}_{h}}
\newcommand{\WEL}{\mathcal{W}_{e}}
\newcommand{\WRE}{\mathcal{W}_{r}}
\newcommand{\WSO}{\mathcal{W}_{s}}
\newcommand{\DES}{\Delta_{es}}
\newcommand{\DRT}{\Delta_{h}}
\newcommand{\DSO}{\Delta_{s}}
\newcommand{\DEL}{\Delta_{e}}
\newcommand{\DRE}{\Delta_{r}}

%\sloppy

\title{Deterministic Integration of Hard and Soft Real-Time Communication
       over Shared-Ethernet}

\author{}
%{Paul D. E. Regnier\inst{1}, George M. Lima\inst{1} }

\address{}
%{Laboratório de Sistemas Distribuídos -- Universidade Federal da Bahia
%  (UFBA)\\
%  CEP 40.170-110 -- Salvador -- BA -- Brazil
%  \email{\{gmlima, pderegnier\}@ufba.br}
%}

\begin{document}

\maketitle

\begin{abstract}
    This paper presents a protocol that makes Ethernet suitable for
    supporting modern real-time systems. Applications that can benefit
    from the proposed protocol are mainly those composed of heterogeneous
	distributed components, which are specified in terms of both hard and soft
    timing constraints. Indeed, using the proposed protocol, hard and soft
    real-time tasks can efficiently and predictably share an Ethernet bus.
    The bus utilization is optimized by an appropriate allocation of the
    available bandwidth into hard and soft communication. Moreover,
    the protocol, compatible with standard Ethernet hardware,
    implements a decentralized medium access control
    that provides a great deal of communication flexibility and reliability.
\end{abstract}

\section{Introduction}

Research on real-time systems have been facing several challenges
in the last few decades. From the application domain perspective,
such systems, once seen as composed by simple, strict and short
hard periodic tasks \cite{Liu73}, typically used for control
loops, nowadays include applications such as telecommunication,
industry, military, aerospace, assets monitoring, automobile etc.
While parts of these systems may contain the usual hard periodic
tasks, requiring known bounded response time and controlled
jitter, other parts may be made of much more complex soft (or
non-hard) tasks to deal with sporadic or aperiodic events as is the
case of multimedia tasks \cite{Liu00}, leading to a considerable
task diversity. Further, from the point of view of their structure,
real-time systems have been moving from centralized to distributed.
This requires a suitable communication network capable of dealing
with the new demands task diversity require. Indeed, network
protocols must deal with different traffic patterns in such a way
that they must be able to provide not only controlled jitter and
bounded message transmission time, as required by the usual hard
tasks, but also high throughput, as demanded by soft and other
non-periodic tasks. As a result, industrial communication
networks, known by being reliable and predictable may, not suffice
anymore due to their usual low bandwidth.

Ethernet has been considered to be a promising alternative for
designing distributed real-time systems. It provides high
bandwidth, it is cheap, efficient and widely used. However, one
cannot consider its direct use in the real-time systems domain.
This is due to its {\em probabilistic} bus arbitration scheme,
which relies on the Binary Exponential Backoff (BEB) algorithm
used by the Carrier Sense Multiple Access with Collision Detection
protocol (CSMA/CD). In short, messages sent by distinct nodes may
collide if they are sent simultaneously. According to the BEB
algorithm, after detecting the collision, the nodes wait a random
time to retransmit their messages. Further collisions may occur,
messages may get lost or may be non-deterministically
delayed~\cite{CSMA/CD01, Wang99, Dolejs04}. Several solutions to
this problem have been proposed \emph{as surveyed} in
\cite{Wang02,Decotignie05}. This
paper follows the software-based approach, which is based on
building an extra layer on top of the Ethernet layer to provide
deterministic communication guarantees without jeopardizing
flexibility neither increasing hardware costs. More specifically,
our solution is based on sharing the Ethernet with the system
nodes, which can efficiently provide broadcast and multicast
communication, facilities required by many real-time systems
\footnote{There are many other solutions, either based on hardware
or software modification. Interested readers can refer to
\cite{Hanssen05,Decotignie05}.}. A brief description on
related work is given in section \ref{sec:relatedWork}

This paper describes a broadcast-oriented software-based
shared-Ethernet protocol that has the following main
characteristics: (a) is capable of dealing with different
communication patterns (eg periodic and aperiodic) and
provide temporal isolation by preventing one from interfering in
the other; (b) is reliable and predictable; (c) is efficient; and
(d) can optimize the bus utilization. The proposed
protocol is presented in more details in section
\ref{sec:doris}

\section{Software-based Shared-Ethernet Approaches to Real-Time Ethernet
         \label{sec:relatedWork}}

Perhaps the simplest deterministic software-based solution is to
divide time into a sequence of slots, each of which is assigned to
a specific system node. Nodes can transmit their message only in
their respective time slot. This scheme, known as Time Division
Multiple Access (TDMA) \cite{Kurose05}, gives a great deal of
communication predictability. This characteristic suits well
industrial applications, composed mainly by hard periodic tasks.
However, when different traffic patterns are considered, TDMA is
too inflexible and inefficient to be recommended. For example, a
node requiring to transmit multimedia related messages may have to
wait for its slot too long even if the bus is not being used.

Token-based protocols are usually more flexible than TDMA. They
use a token to give permission to a node to transmit messages. The
nodes are organized in \emph{some kind of} logical ring and the token
rotates on the ring. Only the token holder node has the right to
transmit on the bus. The token can be explicit or implicit.

Explicit token uses a token message to allow node to transmit.
Whenever a node terminates a transmission, it sends the token to
the next node according to the schedule, like in RETHER
\cite{Venkatrami94} or RTnet \cite{Hanssen05}. Although these
protocols deal with different traffic patterns, they introduce
extra overhead in case of token loss.

\begin{comment}
Explicit token is used by protocols like RETHER
\cite{Venkatrami94} or RTnet \cite{Hanssen05}. Although these
protocols deal with different traffic patterns, they introduce
extra overhead in case of token loss.
\end{comment}

Implicit token protocols based on Timed Packet Release mechanism
(TPR) offer a better alternative \cite{Pritty95, Carreiro03}. In
brief, a token is implicitly passed on to the next node
independently of whether or not the previous node in the ring
transmits its message. In other words, the absence of message
means that a node is giving up its right to use the bus. Thus, the
bus can be utilized more efficiently. However, the speed of
rotating the token must be carefully calculated to fit to the
slowest node on the ring since each node has to observe any bus
activity. Therefore, this approach may suffer from performance
degradation in systems composed of heterogeneous nodes with
different traffic demands.

Other protocols, like FTT \cite{Pedreiras02}, use a master-slave
model to control bus access. Here a special node plays the role of
an arbiter (the master), polling other nodes (the slaves). Slaves
are allowed to transmit their messages only if they get permission
to do so. This model can handle hard and soft traffics
but exhibits single-point of failure, which can be dealt with if
the master is replicated. In any case, there is an asymmetric load
distribution on the net, which may imply problems of scalability
and performance.

In this paper we mix two approaches together, TDMA and implicit
token, to get the best out of each one. TDMA is used to create
two windows to predictably deal with hard and soft
messages, respectively. Inspired by the Virtual Token Protocol
(VTPE) \cite{Carreiro03}, the bus access in each window is
controlled by organizing the nodes in two rings, one for each
window, and by using implicit token so that bus utilization can be
optimized. The proposed protocol, called \doris{}, which stands
for {\em Double Ring Service for Real-Time Ethernet}, is flexible
and efficient. Unlike VTPE, slow nodes do not compromise
performance since while they are processing incoming messages,
fast nodes may use the bus for soft traffic.


\section{DoRiS}
\label{sec:doris}

\doris{} is a collision-free protocol built on top of Ethernet
hardware. Located between the IP and the physical layers of the
Ethernet stack, the protocol works as a logical layer, extending
the CSMA/CD MAC layer.

\doris{} was designed to support hybrid systems where industrials
sensors, actuators and controllers share the communication network
and other soft applications. It is
important to notice that the processing speed and the
communication characteristics of these two types of application
differ to a great extent. Indeed, most industrials
appliances available on the shelf have low processing capacity
compared to Ethernet bandwidth. For example, Carreiro et al. [2003]
assumes that industrial appliances spend up to
$111 \, \mu s$ to process an incoming message of 64B. As the
transmission time on a 100Mbps Ethernet link of such
message is $5.12\,\mu s$, this allows only about $4.6\%$ of bus
utilization for hard real time communication.
On the other hand, multimedia application requires much higher transmission
rates and faster processing nodes. Taking these observations into
consideration, \doris{} provides both temporal guarantees for hard
real-time tasks and high bandwidth access to soft and best effort
ones.

In order to achieve the integration of distinct traffic patterns,
a scheme based on TDMA and virtual token is used. After presenting
the computation model, this scheme will be presented in more
details in the next few sections. We will focus the protocol
description on the functions that guarantee the shared medium
access without collision. As the functions to receive messages
are based on the Ethernet standard functions, they will not be
described. Also, due to lack of space, mechanisms for
implementing node synchronization, group membership and fault
tolerance will not be considered.

\subsection{Computation Model
            \label{sec:model}}

We consider a set of nodes connected to each other through a
shared-Ethernet segment, the \doris{} segment. Each node may run
hard real-time or soft tasks, each of which is uniquely
identified in the system. For the sake of notation, we refer to
the former simply as {\em tasks} while to the latter as {\em
processes} and denote them as the ordered sets
$\TRT=\{T_1,T_2,\ldots,T_{N_{\TRT}}\}$ and $\PSO
=\{P_1,P_2,\ldots,P_{N_{\PSO}}\}$, respectively. These sets
represent the two logical rings of DoRiS.

Received messages are processed by the tasks within a maximum
processing time, denoted by $\pi$. This time is usually associated
to message processing by industrial appliances (micro-controllers,
sensors etc). We assume that these appliances, called hereafter
{\em slow nodes}, need temporal guarantees and that their messages
are short, usually periodic, and have hard real-time constraints.
Such messages, called \emph{slot messages}, are assumed to have a
constant length of 64B and are transmitted through the network
within a maximum transmission time $\delta \ll \pi$. We also
consider that the task processing time regarding message
transmission is incorporated into the the task computation time
and so can be neglected during the protocol description.

We assume the publish-subscribe communication
model~\cite{Dolejs04} according to which whenever a task or
process has a message to send, it transmits such a message using the
Ethernet broadcast standard address (48 address bits set to 1).
Each task/process receives and processes every message.
Based on the source address, they then decide wether they are
interested in the message. In practical applications, tasks may
not have to process all messages or may drop unused messages.
However, for the sake of model simplification we assume here that
all hard real time messages are fully processed by the tasks.
%Shall we distinguish slot and soft message using the type field ??? 

As mentioned before, if only slow nodes are present in the
\doris{} segment, the bus may be under-utilized. However, if there
are fast nodes connected to the bus, \doris{} allows them to use
this spare bandwidth. Assuming that nodes are equipped with
receiving buffers, receiving and processing of slot messages are
independent actions that can happen simultaneously. Therefore, the
maximum bandwidth \emph{rate} used for real-time traffic is
$B_m = \delta / \pi$. It is important to notice that $B_m$
indicates the bound above which buffer overflows occur since
the slowest node will receive more slot messages than it
can process. Also, note that since there are buffers at
the nodes, more than one message can be sent in a row.

\subsection{The Protocol Structure}

The communication on a \doris{} segment is structured as an
infinity sequence of consecutive time slots, called {\em
elementary sequences} and denoted $ES_k, k \in Nat-\{0\}$.
Each $ES_k$ is itself divided into two windows,
$\WRT$ and $\WSO$, respectively associated to hard and
soft real-time traffics. Tasks send messages only in $\WRT$ while
processes use $\WSO$ to transmit theirs. The size of these two
windows are respectively denoted $\DRT$ and $\DSO$. Thus, the
elementary sequence size is defined by $\DES = \DRT + \DSO$.

An $i$-cycle is defined as an ordered list of $N_T$ elementary
sequence that begins by $ES_k$ with $i = (k-1)mod(N_T) + 1$.
Whenever indexes are not relevant, an $i$-cycle and $ES_k$
are simply denoted cycle and ES. Figure \ref{fig:dorisStruct}
illustrates a cycle focusing on the $ES_i$ and beginning
by $ES_1$.

\begin{figure}[ht]
  \index{fig!dorisStruct}
   \centering
  \input{fig/dorisStruct.pstex_t}
  \caption{The $\mathrm{N_T}$ elementary sequences of a \doris{} $1$-cycle
  \label{fig:dorisStruct}}
\end{figure}

We assume that nodes are equipped with a local timer. For
simplicity, if $T_i$ (or $P_i$) and $T_j$ (or $P_j$) are two tasks
(processes) located in the same node, their local timers $t_i$
and $t_j$, instances of the node timer, are equal.
These timers are used to divide the bandwidth into elementary
sequences. For that purpose, they assume values from $0$ to
$\DES$ and are reset periodically at the end of each ES.
Each task $T_i$ and process $P_i$ maintains also a local
integer counter, respectively denoted $K^T_{i}$ and $K^P_{j}$.
Local timers and counters are used to organize the token circulation
between both rings $\TRT$ and $\PSO$ as will be seen in the following
two sections.

To allow some flexibility and scheduling policy, the hard
real-time window is further divided into two sub-windows, the
elementary ($\WEL$) and the reservation ($\WRE$) windows, as
illustrated in Figure \ref{fig:dorisStruct} for the
$i^{\mathrm{th}}$ ES. Messages sent in these two windows are
called elementary and reservation messages, respectively. $\WRE$
is used to offer a reservation mechanism, which will be explained
in section \ref{sec:reservation} Both elementary and reservation
messages are slot messages.


\subsection{The Hard Real-Time Ring}

\subsubsection{The Elementary Window}

Tasks are logically organized in a ring where an implicit token
rotates. Only the task that holds the token can have access to the
medium. To organize the virtual token passing, \doris{} combines both
logical and temporal conditions.

A task $T_i$ is said to hold the token in $\WEL$ if its counter
$K^T_i$ equals $i$ and if its timer is equal to zero, that
is when a new elementary window just begins. We assume 
here that the timer drift is bounded by the inter-frame gap
time (IFG) \cite{ControlNet97} (this parameter of the Ethernet
standard \cite{CSMA/CD01} is defined to be equal to the time a
signal takes to propagate on the longest shared-Ethernet segment
allowed by the standard). We will see at the end how this 
can be guaranteed by the protocol. Thus, we express the equality
condition by means of an inequality, where $t_i$ has to be less
than IFG. The following predicate formalizes these conditions:

\begin{tabular}{ l l }
  $ElemHolder(i) \defeq$ & $(0 \leqslant t_{i} < IFG) \;
                             \wedge \; (K^T_{i} = i)$
\end{tabular}

Whenever $ElemHolder(i)$ becomes true, $T_i$ broadcasts an
elementary message by executing the $sendElemMsg(i)$ operation,
which consists of transmitting its local counter $K^T_i$, its
reservation list (see next section), and its optional data if
there are any. Sending an elementary message in each ES makes it
easier to implement failure detectors and gives communication
regularity, characteristics required by hard real-time tasks.

At the beginning of each $i$-cycle the counter $K_i^T$ equals $i$ and
is (periodically) incremented by 1 at the end of each ES. As
there are exactly $N_T$ elementary sequences in each cycle, every
task in $\TRT$ periodically receives the token in $\WEL$ once
per cycle.

Observe that, as each ES contains one elementary message, tasks
can synchronize themselves by using the End-Of-Frame interrupt of
the broadcast message. Also, if an elementary message suffers an
omission fault, the progression of the local counters will not be
blocked, as they rely on local timers. As a consequence, the
maximum drift of local timers is bounded according to the
synchronization protocol and the number of consecutive omissions
assumed to be tolerated \cite{PCSP02}.

\subsubsection{The Reservation Window}
\label{sec:reservation}

The reservation scheme is used to implement some message priority
policy by means of the reservation windows, which make
some extra bandwidth available for the tasks.
To implement this scheme each task $T_i$ sends its
reservation list upon the
execution of $sendElemMsg(i)$,
as we described in the previous section.
For each task $T_i$, this list is a possibly empty subset of
$\{1, 2, \dotsc, N_{T}\} - \{i\}$ that indicates the elementary
sequences of the  $i$-cycle in which $T_i$ will use $\WRE$ to
transmit extra data. For example, reservation list $\{2,4\}$ sent
by $T_3$ means that $T_3$ requests $\WRE^2$ and $\WRE^4$ in the
$3$-cycle. If $T_i$ sends an empty list, no reservation is requested.

As can be noted, the reservation list size is up to $N_T-1$ and can
be implemented as a bit vector. An efficient alternative
for of (implicitly) implementing this list
is to send the number of windows requested.
In this case, a request carrying $k>0$ would mean that the next $k$
free windows were to be reserved. This would imply that
$\lceil \log_2 (N_T-1) \rceil$ message bits must be used to
represent the implicit list instead of $N_T-1$ bits.
Nevertheless, one can find out
a trade-off between the list size and the maximum number of $\WRE$ per
task that could be reserved. We consider here the list size as an
implementation detail and do not impose any restriction to it.

When a task receives a reservation list, it updates a boolean vector of
size $N_{\mathcal{T}}$, denoted $\Gamma_i$.
If the entry $\Gamma_i[j]$ is true, the $\WRE^j$ is reserved.
Otherwise, such a window is free.
The value true for $\Gamma_i[j]$ is valid only for the corresponding $j$-cycle.
Thus, $\Gamma_i[j]$ is reset after $N_T$ ES have been finished since the time
$\Gamma_i[j]$ was set.

It is important to note that
{\em at least one reservation window per cycle is guaranteed to the 
tasks}. Hence, considering task $T_i$, it is the first one to
have the right to request the reservation of $\WRE^{i+N_T}$. Thus,
no other task $T_j$ ($j < i$) can have reserved $\WRE^{i+N_T}$ before.

It is clear that for a task to transmit its message in a reservation window, it
has to be sure that the reservation procedure was successful and such
a reservation window is not reserved by any other task.
For example, omission faults of elementary message could make
$\Gamma_i$ inconsistent.
The protocol deals with this requirements in a very efficient way
by establishing a reservation condition.
Indeed, $T_i$ may only request a reservation if its
{\em state is consistent}, which
is formalized by the following predicate:

\begin{tabular}{ l p{14cm} }
  $Consistency(\Gamma_i) \defeq$ & $T_i$ has received all elementary \newline
                                 messages sent in the previous $i$-cycle\\
\end{tabular}

Let $\DEL=\delta + IFG$ be the size of $\WEL$. A task $T_i$
is said to hold the token in $\WRE^j$ if it has a reservation for
$\WRE^j$ and if its timer $t_i$ is in the interval
$[\DEL , \DEL + IFG)$. More formally,

\begin{tabular}{ l p{14cm} }
  $ReserHolder(i) \defeq$ & $(\DEL \leqslant t_i < \DEL + IFG)
                  \; \wedge \; (\Gamma_i[K_i^T] = true)$\\
\end{tabular}

It is important to emphasize that the reservation scheme offers
interesting properties. First, $\Gamma_i$ can be efficiently implemented.
Indeed, it is a bit vector and
there is no need of clocks to reset the vale of $\Gamma_i$  since
the elementary sequence periodicity can be used as a logical clock.
Second, as we have seen,
reservations are always safely carried out even when faults
are considered. Third, there are three implicity priority levels:
one that uses elementary windows only;
the other is regarding the guaranteed reservation window;
and the third that makes use of the free (but not guaranteed)
reservation windows.

\subsection{The Soft Ring $\PSO$}

As in the hard ring, processes
use their timers to control the soft ring, using
elementary messages as temporal
references. In brief, the end of every $\WRT$ works as a pulse,
marking the beginning of the soft windows.
Like the VTPE protocol \cite{Carreiro03},
this is actually a decentralized version of
the Timed Packet Release mechanism~\cite{Pritty95}
since no node/process plays a central role
for sending the pulse.

Unlike the hard ring, processes do not have to send messages always.
The token rotates based on the carrier sense mechanism provided by
Ethernet. We introduce $d$, a parameter of the procol to define the 
following TPR mechanism. At the beginning
of each $\WSO$, each process senses the medium. 
For each period $d$ that it senses the medium iddle, it
increments its local counter $K_i^P$.
Otherwise, some process is transmitting and the medium is busy.
In this case, each process waits for the
End-Of-Frame interrupt associated to the current transmission and then
increments its counter.
The parameter $d$ is chosen to be $1 \, \mu s$ (considering a 100 MB bus).
This ensures unambiguous detection of the start of a packet
transmitted by a previous node \cite{Pritty95}.

We say that a process $P_i$ is allowed to transmit when the following
enabling predicate holds:

\begin{tabular}{ l p{14cm} }
  $SoftHolder(i) \defeq$ & ($\DRT \leqslant t_i < \DRT + \DSO) \; \wedge \;$
                  (Medium is iddle) $\; \wedge \;(K_{i}^P = i)$\\
\end{tabular}

%This value, is just greater than the IFG of 96 bits time
%($0.96 \, \mu s$).
While the token rotates, the remaining time
in $\WSO$ decreases. Thus, a process $P_i$ could receive the token
without enough time to transmit its message in the current $\WSO$.
As this could happen an arbitrary number of times, a process might
be undefinitely unable to transmit its message.
To solve this problem, we define a ``STOP'' message as a special
slot message that stops the token time passing in the current window.
Note that a STOP message is to distinguish the case
that a process has nothing to send from the case it has not enough time
to transmit. The process that sends a STOP message will be the first
to hold the token in the next $\WSO$.
As $\WSO^i$ ends when the remaining time is equal to $\delta$, 
a process that receives the token always has enough time in the
current $\WSO^i$ to send a STOP message. 

Its important to consider fault scenarios. Indeed,
a process $P_i$ may suffer a transient or processing
timing fault. In this case, its local counter
$K_i^P$ may be out of date. There are two cases that have to be
dealt with. First, if $P_i$ observes an empty $\WSO$, the process with
the smaller identifier is assumed to first hold
the token in the next $\WSO$. This is done by
resetting $K_i^T$ to 1 at all processes. Second,
if $P_i$ observes a soft message transmission, it
identifies the message sender from its source address.
Using the ES beginning instant and the message Start-Of-Frame
instant, $P_i$ localizes the token.
As can be noted, the protocol is safe in both cases.


\subsection{Analises}
%\label{sec:conclusion}

The \doris{} temporal properties will not be exposed in details 
in this paper due to the lake of space. Nevertheless, we must
emphasize some important points of our protocol: 

\begin{comment}
As two slot messages may be sent in each
ES, every slow nodes needs $2 \pi$ to process them.
%($\pi$ is the processing time of a slot message by the slowest node).
The existence of buffers at the nodes allows a task to process a
message while receiving another, thus, $\DSO$ has to be greater
than $2 \pi - \DRT$.
\end{comment}
Choosing the minimum value $\DSO = 2 \pi - \DRT$ allowed by
the processing bound (cf. section \ref{sec:model}) permits to
maximize the bandwidth available for $\TRT$. Thus, the bandwidth
$B_{h}$ available for the real time ring is: $B_{h} = 2 \delta /
\DES$. As $\DES = \DRT + \DSO$, this means that
$B_{h} = \delta / \pi = 4,6\%$

In order to allow any size of message inside the range of the
Ethernet standard (fom 64 to 1518 bytes), which corresponds to a
temporal range from $\delta = 5.12$ to $\delta_m = 121.44 \, \mu
s$, we assume that $2 \pi$ is greater than $\delta_m$.
Practically, we assume that $\pi = 111 \; \mu s$ as in \cite{Carreiro03}.

The remaining bandwidth (95,4\%) is used by the soft ring. In the
worst case, if only one process wants to tranmit, it can suffer the 
maximum delay of $N_T \, d$. Thus, if all processes wants to transmit,
the last to receive the token may waits the worst token rotation time
of $N_T \, d + (N_T - 1) \DSO$.

\begin{comment}

In a scenario where a $\WSO$ contains one message of size $\delta_m$,
the remaining time available for the timed token circulation
mechanism is $\DSO -\delta_m - 3 d (97 \; \mu s)$, as the STOP
mechanism consumes $3 d$.
Thus the number of soft nodes that the token may visit
during this $\WSO$ is aproximatively 85.

Observe that if no reservation are made in a specific elementary
sequence, the corresponding slot remains empty, i.e. the medium
remains iddle. This causes a certain waste of the bandwidth (about
2.3\% cf. section \ref{???}) which could be improved for
the soft communication. Nevertheless, to avoid that waste,
the soft processes should observe the hard real time
communication and maintain a consistent $\Gamma$ tuple. This would
generates new faults scenariis in case of message loss. To let the
protocol simpler and safer, we choose a deterministic and periodic
mecanism that provides efficient fault detection and isolation of
both kind of communication.

Let the token rotation time THT be the time between two elementary
message send by a given process. THT is constant and is equal to the
duration of a cycle: $N_T \DES$.

Thus the total bandwidth available for a given task is $B_h / N_T$.

In the ASYNC case and if $\pi$ is much smaller than $\delta_m$, it
is possible to increase the value of $\alpha$ to optimize the
division of the bandwidth between the two rings.
\end{comment}

\section{Conclusion}
\label{sec:conclusion}

\doris{}, a protocol that allows the co-existence of both hard and
soft real-time traffics
on the same Ethernet segment was described. \doris{} can offer periodicity
for hard real-time messages and high transmission rates to soft ones.
Both types of real-time traffic are temporally isolated from each other
and the bus utilization can be optimized.

The described protocol is currently been formally specified and then will be
implemented, possibly using some open source real-time operating system.
Further protocol functionalities must be considered in future work.
For example, appropriate priority polices can be used to
take advantage of the reservation mechanism. Also, mechanisms such as
membership control and dynamic reconfiguration can play an important role
in increasing the reliability and flexibility of \doris{}.

\bibliographystyle{sbc}
\bibliography{bib}

\end{document}
